{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment\n",
    "# experiment = Experiment(api_key=\"xktj4EX0zB8YcQ3BEaFwOQYpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.datasets as ds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = ds.load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 3\n",
    "nb_epoch = 30\n",
    "\n",
    "lmda = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logistic_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim, input_dim=input_dim,\n",
    "                    kernel_regularizer=l2(lmda),\n",
    "                    activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = build_logistic_model(input_dim, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.1585 - acc: 0.5185 - val_loss: 0.8993 - val_acc: 0.6000\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 385us/step - loss: 1.0910 - acc: 0.5407 - val_loss: 0.8473 - val_acc: 0.6000\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 370us/step - loss: 1.0335 - acc: 0.5704 - val_loss: 0.8028 - val_acc: 0.6000\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 392us/step - loss: 0.9826 - acc: 0.6296 - val_loss: 0.7640 - val_acc: 0.6000\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.9377 - acc: 0.6593 - val_loss: 0.7305 - val_acc: 0.7333\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 370us/step - loss: 0.8989 - acc: 0.6593 - val_loss: 0.7025 - val_acc: 0.7333\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 363us/step - loss: 0.8653 - acc: 0.6667 - val_loss: 0.6777 - val_acc: 0.8000\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 289us/step - loss: 0.8351 - acc: 0.7037 - val_loss: 0.6547 - val_acc: 0.8000\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8060 - acc: 0.7111 - val_loss: 0.6357 - val_acc: 0.8667\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 215us/step - loss: 0.7818 - acc: 0.7185 - val_loss: 0.6194 - val_acc: 0.8667\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.7609 - acc: 0.7481 - val_loss: 0.6050 - val_acc: 0.8667\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.7422 - acc: 0.7704 - val_loss: 0.5924 - val_acc: 0.8667\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 230us/step - loss: 0.7253 - acc: 0.7704 - val_loss: 0.5805 - val_acc: 0.8667\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.7095 - acc: 0.8000 - val_loss: 0.5699 - val_acc: 0.8667\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.6949 - acc: 0.8074 - val_loss: 0.5605 - val_acc: 0.8667\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.6819 - acc: 0.8074 - val_loss: 0.5525 - val_acc: 0.8667\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.6706 - acc: 0.8148 - val_loss: 0.5450 - val_acc: 0.8667\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6598 - acc: 0.8148 - val_loss: 0.5384 - val_acc: 0.8667\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.6502 - acc: 0.8148 - val_loss: 0.5321 - val_acc: 0.9333\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6411 - acc: 0.8148 - val_loss: 0.5267 - val_acc: 0.9333\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.6328 - acc: 0.8148 - val_loss: 0.5217 - val_acc: 0.9333\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6257 - acc: 0.8148 - val_loss: 0.5177 - val_acc: 0.9333\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.6193 - acc: 0.8148 - val_loss: 0.5138 - val_acc: 0.9333\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6134 - acc: 0.8148 - val_loss: 0.5100 - val_acc: 0.9333\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.6075 - acc: 0.8148 - val_loss: 0.5068 - val_acc: 0.9333\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6024 - acc: 0.8148 - val_loss: 0.5041 - val_acc: 0.9333\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.5978 - acc: 0.8222 - val_loss: 0.5011 - val_acc: 0.9333\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 230us/step - loss: 0.5933 - acc: 0.8370 - val_loss: 0.4985 - val_acc: 0.9333\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.5888 - acc: 0.8370 - val_loss: 0.4965 - val_acc: 0.9333\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.5851 - acc: 0.8370 - val_loss: 0.4944 - val_acc: 0.9333\n",
      "Running Fold 2 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.4970 - acc: 0.2370 - val_loss: 1.4975 - val_acc: 0.2000\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 1.4014 - acc: 0.3111 - val_loss: 1.3966 - val_acc: 0.2667\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 1.3197 - acc: 0.4074 - val_loss: 1.3072 - val_acc: 0.4667\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 1.2479 - acc: 0.4815 - val_loss: 1.2330 - val_acc: 0.4667\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 1.1879 - acc: 0.5037 - val_loss: 1.1680 - val_acc: 0.6000\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 1.1351 - acc: 0.5407 - val_loss: 1.1124 - val_acc: 0.6000\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 1.0896 - acc: 0.5630 - val_loss: 1.0645 - val_acc: 0.6667\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 1.0498 - acc: 0.5704 - val_loss: 1.0231 - val_acc: 0.6667\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 1.0151 - acc: 0.5704 - val_loss: 0.9872 - val_acc: 0.6667\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.9844 - acc: 0.6074 - val_loss: 0.9546 - val_acc: 0.6667\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.9561 - acc: 0.6222 - val_loss: 0.9259 - val_acc: 0.6667\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.9313 - acc: 0.6222 - val_loss: 0.9000 - val_acc: 0.6667\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.9086 - acc: 0.6444 - val_loss: 0.8765 - val_acc: 0.6667\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.8876 - acc: 0.6519 - val_loss: 0.8550 - val_acc: 0.6667\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.8685 - acc: 0.6519 - val_loss: 0.8357 - val_acc: 0.6667\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.8512 - acc: 0.6667 - val_loss: 0.8189 - val_acc: 0.7333\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8354 - acc: 0.6667 - val_loss: 0.8030 - val_acc: 0.7333\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.8208 - acc: 0.6741 - val_loss: 0.7880 - val_acc: 0.7333\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.8070 - acc: 0.6741 - val_loss: 0.7743 - val_acc: 0.7333\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.7938 - acc: 0.6741 - val_loss: 0.7616 - val_acc: 0.8000\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7814 - acc: 0.6815 - val_loss: 0.7495 - val_acc: 0.8000\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.7698 - acc: 0.6815 - val_loss: 0.7385 - val_acc: 0.8000\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.7591 - acc: 0.6815 - val_loss: 0.7285 - val_acc: 0.8000\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 230us/step - loss: 0.7492 - acc: 0.6889 - val_loss: 0.7189 - val_acc: 0.8000\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.7400 - acc: 0.7037 - val_loss: 0.7100 - val_acc: 0.8000\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7309 - acc: 0.7185 - val_loss: 0.7018 - val_acc: 0.8000\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.7227 - acc: 0.7333 - val_loss: 0.6936 - val_acc: 0.8000\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.7144 - acc: 0.7333 - val_loss: 0.6861 - val_acc: 0.8000\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7070 - acc: 0.7481 - val_loss: 0.6792 - val_acc: 0.8667\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.6999 - acc: 0.7556 - val_loss: 0.6727 - val_acc: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 3 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.3196 - acc: 0.2370 - val_loss: 1.2574 - val_acc: 0.1333\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 266us/step - loss: 1.2318 - acc: 0.4667 - val_loss: 1.1748 - val_acc: 0.5333\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 1.1590 - acc: 0.5037 - val_loss: 1.1043 - val_acc: 0.6000\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 1.0958 - acc: 0.5259 - val_loss: 1.0451 - val_acc: 0.6000\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 296us/step - loss: 1.0424 - acc: 0.5481 - val_loss: 0.9955 - val_acc: 0.6000\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 304us/step - loss: 0.9971 - acc: 0.5778 - val_loss: 0.9550 - val_acc: 0.6000\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.9597 - acc: 0.6074 - val_loss: 0.9195 - val_acc: 0.7333\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.9269 - acc: 0.6074 - val_loss: 0.8896 - val_acc: 0.7333\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.8987 - acc: 0.6444 - val_loss: 0.8630 - val_acc: 0.7333\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.8730 - acc: 0.6741 - val_loss: 0.8399 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.8511 - acc: 0.7037 - val_loss: 0.8193 - val_acc: 0.8000\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8311 - acc: 0.7333 - val_loss: 0.8016 - val_acc: 0.8000\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.8133 - acc: 0.7333 - val_loss: 0.7858 - val_acc: 0.8000\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.7974 - acc: 0.7407 - val_loss: 0.7715 - val_acc: 0.8000\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.7830 - acc: 0.7481 - val_loss: 0.7589 - val_acc: 0.8000\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.7701 - acc: 0.7704 - val_loss: 0.7477 - val_acc: 0.8667\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.7584 - acc: 0.7778 - val_loss: 0.7372 - val_acc: 0.8667\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.7472 - acc: 0.7926 - val_loss: 0.7277 - val_acc: 0.8667\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.7373 - acc: 0.7778 - val_loss: 0.7190 - val_acc: 0.8667\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.7277 - acc: 0.7852 - val_loss: 0.7109 - val_acc: 0.8667\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.7190 - acc: 0.7852 - val_loss: 0.7036 - val_acc: 0.8667\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.7110 - acc: 0.7852 - val_loss: 0.6967 - val_acc: 0.8667\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7031 - acc: 0.7778 - val_loss: 0.6904 - val_acc: 0.8667\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.6959 - acc: 0.7852 - val_loss: 0.6846 - val_acc: 0.8667\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6895 - acc: 0.7778 - val_loss: 0.6791 - val_acc: 0.8667\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 215us/step - loss: 0.6830 - acc: 0.7778 - val_loss: 0.6740 - val_acc: 0.8667\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6771 - acc: 0.7778 - val_loss: 0.6691 - val_acc: 0.8667\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.6713 - acc: 0.7778 - val_loss: 0.6646 - val_acc: 0.8667\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.6660 - acc: 0.7852 - val_loss: 0.6604 - val_acc: 0.8667\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 230us/step - loss: 0.6611 - acc: 0.7926 - val_loss: 0.6564 - val_acc: 0.8667\n",
      "Running Fold 4 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.5460 - acc: 0.3111 - val_loss: 1.4593 - val_acc: 0.4667\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 1.4180 - acc: 0.3333 - val_loss: 1.3560 - val_acc: 0.5333\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 1.3081 - acc: 0.3852 - val_loss: 1.2641 - val_acc: 0.6000\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 1.2107 - acc: 0.4519 - val_loss: 1.1886 - val_acc: 0.6667\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 1.1301 - acc: 0.4667 - val_loss: 1.1268 - val_acc: 0.6667\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 1.0636 - acc: 0.5111 - val_loss: 1.0702 - val_acc: 0.6667\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 1.0028 - acc: 0.5259 - val_loss: 1.0261 - val_acc: 0.6667\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.9553 - acc: 0.5333 - val_loss: 0.9889 - val_acc: 0.6667\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 230us/step - loss: 0.9153 - acc: 0.5778 - val_loss: 0.9569 - val_acc: 0.6667\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8808 - acc: 0.6148 - val_loss: 0.9286 - val_acc: 0.6667\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.8500 - acc: 0.6444 - val_loss: 0.9032 - val_acc: 0.6667\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8230 - acc: 0.6593 - val_loss: 0.8824 - val_acc: 0.6667\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8005 - acc: 0.6889 - val_loss: 0.8627 - val_acc: 0.6667\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.7803 - acc: 0.7037 - val_loss: 0.8468 - val_acc: 0.6667\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.7628 - acc: 0.7481 - val_loss: 0.8322 - val_acc: 0.6667\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.7475 - acc: 0.7556 - val_loss: 0.8203 - val_acc: 0.6000\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.7340 - acc: 0.7704 - val_loss: 0.8097 - val_acc: 0.6667\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.7224 - acc: 0.7778 - val_loss: 0.7995 - val_acc: 0.6667\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7112 - acc: 0.7926 - val_loss: 0.7906 - val_acc: 0.6667\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 289us/step - loss: 0.7014 - acc: 0.7852 - val_loss: 0.7823 - val_acc: 0.6667\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.6924 - acc: 0.7852 - val_loss: 0.7742 - val_acc: 0.6667\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 230us/step - loss: 0.6840 - acc: 0.7778 - val_loss: 0.7673 - val_acc: 0.6667\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6762 - acc: 0.8000 - val_loss: 0.7611 - val_acc: 0.6667\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6697 - acc: 0.8000 - val_loss: 0.7555 - val_acc: 0.6667\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6631 - acc: 0.7926 - val_loss: 0.7498 - val_acc: 0.6667\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.6570 - acc: 0.7926 - val_loss: 0.7452 - val_acc: 0.6667\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6517 - acc: 0.7926 - val_loss: 0.7400 - val_acc: 0.6667\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6463 - acc: 0.7778 - val_loss: 0.7355 - val_acc: 0.6667\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.6413 - acc: 0.7778 - val_loss: 0.7317 - val_acc: 0.6667\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.6369 - acc: 0.7852 - val_loss: 0.7280 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 5 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.5265 - acc: 0.3111 - val_loss: 1.5933 - val_acc: 0.3333\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 1.3941 - acc: 0.3407 - val_loss: 1.4677 - val_acc: 0.4000\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 1.2769 - acc: 0.3704 - val_loss: 1.3645 - val_acc: 0.4000\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 1.1813 - acc: 0.4148 - val_loss: 1.2779 - val_acc: 0.5333\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 1.1016 - acc: 0.4667 - val_loss: 1.2039 - val_acc: 0.5333\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 1.0345 - acc: 0.5111 - val_loss: 1.1387 - val_acc: 0.5333\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.9762 - acc: 0.6074 - val_loss: 1.0856 - val_acc: 0.6000\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.9290 - acc: 0.7037 - val_loss: 1.0383 - val_acc: 0.6000\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.8874 - acc: 0.7259 - val_loss: 0.9991 - val_acc: 0.6667\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.8530 - acc: 0.7778 - val_loss: 0.9664 - val_acc: 0.6667\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8240 - acc: 0.8148 - val_loss: 0.9390 - val_acc: 0.7333\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8000 - acc: 0.8148 - val_loss: 0.9146 - val_acc: 0.7333\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.7791 - acc: 0.8148 - val_loss: 0.8927 - val_acc: 0.7333\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.7603 - acc: 0.8222 - val_loss: 0.8739 - val_acc: 0.7333\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.7440 - acc: 0.8222 - val_loss: 0.8574 - val_acc: 0.7333\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.7300 - acc: 0.8222 - val_loss: 0.8428 - val_acc: 0.7333\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.7178 - acc: 0.8296 - val_loss: 0.8288 - val_acc: 0.7333\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.7061 - acc: 0.8444 - val_loss: 0.8167 - val_acc: 0.7333\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 289us/step - loss: 0.6961 - acc: 0.8444 - val_loss: 0.8062 - val_acc: 0.7333\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6871 - acc: 0.8444 - val_loss: 0.7966 - val_acc: 0.7333\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6793 - acc: 0.8444 - val_loss: 0.7874 - val_acc: 0.7333\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.6715 - acc: 0.8444 - val_loss: 0.7794 - val_acc: 0.7333\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6647 - acc: 0.8593 - val_loss: 0.7718 - val_acc: 0.7333\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.6585 - acc: 0.8593 - val_loss: 0.7653 - val_acc: 0.7333\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 289us/step - loss: 0.6530 - acc: 0.8593 - val_loss: 0.7586 - val_acc: 0.7333\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.6477 - acc: 0.8593 - val_loss: 0.7522 - val_acc: 0.7333\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 326us/step - loss: 0.6426 - acc: 0.8593 - val_loss: 0.7462 - val_acc: 0.7333\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.6378 - acc: 0.8667 - val_loss: 0.7401 - val_acc: 0.7333\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6333 - acc: 0.8667 - val_loss: 0.7353 - val_acc: 0.7333\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.6293 - acc: 0.8667 - val_loss: 0.7306 - val_acc: 0.7333\n",
      "Running Fold 6 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.2591 - acc: 0.3630 - val_loss: 1.1258 - val_acc: 0.4000\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 1.1532 - acc: 0.4074 - val_loss: 1.0305 - val_acc: 0.6000\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 1.0628 - acc: 0.4889 - val_loss: 0.9536 - val_acc: 0.6000\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.9901 - acc: 0.6222 - val_loss: 0.8908 - val_acc: 0.7333\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.9300 - acc: 0.7111 - val_loss: 0.8403 - val_acc: 0.8667\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.8815 - acc: 0.7630 - val_loss: 0.7984 - val_acc: 0.8667\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.8407 - acc: 0.7852 - val_loss: 0.7630 - val_acc: 0.8000\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 437us/step - loss: 0.8059 - acc: 0.8000 - val_loss: 0.7345 - val_acc: 0.8000\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.7775 - acc: 0.7926 - val_loss: 0.7094 - val_acc: 0.8000\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.7526 - acc: 0.8000 - val_loss: 0.6883 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7314 - acc: 0.8074 - val_loss: 0.6708 - val_acc: 0.8667\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7130 - acc: 0.8148 - val_loss: 0.6559 - val_acc: 0.8667\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6977 - acc: 0.8074 - val_loss: 0.6436 - val_acc: 0.8667\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 289us/step - loss: 0.6849 - acc: 0.8148 - val_loss: 0.6324 - val_acc: 0.8667\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.6728 - acc: 0.8148 - val_loss: 0.6228 - val_acc: 0.8667\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6626 - acc: 0.8148 - val_loss: 0.6143 - val_acc: 0.8667\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.6534 - acc: 0.8074 - val_loss: 0.6068 - val_acc: 0.8667\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.6451 - acc: 0.8074 - val_loss: 0.6002 - val_acc: 0.8667\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.6377 - acc: 0.8074 - val_loss: 0.5944 - val_acc: 0.8667\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6309 - acc: 0.8074 - val_loss: 0.5891 - val_acc: 0.8667\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6250 - acc: 0.8074 - val_loss: 0.5843 - val_acc: 0.8667\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6194 - acc: 0.8074 - val_loss: 0.5798 - val_acc: 0.8667\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.6144 - acc: 0.8074 - val_loss: 0.5755 - val_acc: 0.8667\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6096 - acc: 0.8148 - val_loss: 0.5716 - val_acc: 0.8667\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.6050 - acc: 0.8000 - val_loss: 0.5683 - val_acc: 0.8667\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6011 - acc: 0.7926 - val_loss: 0.5652 - val_acc: 0.8000\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.5974 - acc: 0.8000 - val_loss: 0.5624 - val_acc: 0.8000\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.5942 - acc: 0.8000 - val_loss: 0.5599 - val_acc: 0.8000\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.5911 - acc: 0.8074 - val_loss: 0.5576 - val_acc: 0.8000\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.5883 - acc: 0.8000 - val_loss: 0.5554 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 7 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 1.0957 - acc: 0.4222 - val_loss: 1.1156 - val_acc: 0.3333\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 1.0391 - acc: 0.4889 - val_loss: 1.0489 - val_acc: 0.4000\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 253us/step - loss: 0.9925 - acc: 0.5630 - val_loss: 0.9915 - val_acc: 0.4667\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.9522 - acc: 0.6667 - val_loss: 0.9413 - val_acc: 0.6667\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.9167 - acc: 0.6889 - val_loss: 0.8986 - val_acc: 0.7333\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.8866 - acc: 0.7111 - val_loss: 0.8634 - val_acc: 0.8000\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.8607 - acc: 0.7185 - val_loss: 0.8320 - val_acc: 0.8000\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.8376 - acc: 0.7333 - val_loss: 0.8049 - val_acc: 0.8667\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.8174 - acc: 0.7407 - val_loss: 0.7827 - val_acc: 0.8667\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.8000 - acc: 0.7481 - val_loss: 0.7621 - val_acc: 0.8667\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.7838 - acc: 0.7778 - val_loss: 0.7438 - val_acc: 0.8667\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.7695 - acc: 0.7926 - val_loss: 0.7279 - val_acc: 0.8667\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.7563 - acc: 0.7926 - val_loss: 0.7137 - val_acc: 0.8667\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.7446 - acc: 0.8148 - val_loss: 0.7009 - val_acc: 0.8667\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.7338 - acc: 0.8148 - val_loss: 0.6896 - val_acc: 0.8667\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.7242 - acc: 0.8148 - val_loss: 0.6793 - val_acc: 0.8667\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.7151 - acc: 0.8148 - val_loss: 0.6701 - val_acc: 0.8667\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.7068 - acc: 0.8148 - val_loss: 0.6615 - val_acc: 0.8667\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6990 - acc: 0.8222 - val_loss: 0.6533 - val_acc: 0.8667\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6916 - acc: 0.8222 - val_loss: 0.6459 - val_acc: 0.8667\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6847 - acc: 0.8222 - val_loss: 0.6394 - val_acc: 0.8667\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.6783 - acc: 0.8370 - val_loss: 0.6334 - val_acc: 0.8667\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6724 - acc: 0.8444 - val_loss: 0.6275 - val_acc: 0.8667\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6668 - acc: 0.8444 - val_loss: 0.6222 - val_acc: 0.8667\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6613 - acc: 0.8519 - val_loss: 0.6168 - val_acc: 0.8667\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6562 - acc: 0.8519 - val_loss: 0.6120 - val_acc: 0.8667\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.6513 - acc: 0.8667 - val_loss: 0.6073 - val_acc: 0.8667\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6466 - acc: 0.8667 - val_loss: 0.6031 - val_acc: 0.8667\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6423 - acc: 0.8667 - val_loss: 0.5992 - val_acc: 0.8667\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.6383 - acc: 0.8667 - val_loss: 0.5956 - val_acc: 0.8667\n",
      "Running Fold 8 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 1s 4ms/step - loss: 0.7271 - acc: 0.8444 - val_loss: 0.9156 - val_acc: 0.6667\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.7189 - acc: 0.8444 - val_loss: 0.9056 - val_acc: 0.6667\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.7116 - acc: 0.8444 - val_loss: 0.8959 - val_acc: 0.6667\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7044 - acc: 0.8519 - val_loss: 0.8868 - val_acc: 0.6667\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6978 - acc: 0.8519 - val_loss: 0.8784 - val_acc: 0.6667\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6918 - acc: 0.8519 - val_loss: 0.8707 - val_acc: 0.6667\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6860 - acc: 0.8519 - val_loss: 0.8629 - val_acc: 0.6667\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6805 - acc: 0.8519 - val_loss: 0.8556 - val_acc: 0.6667\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6752 - acc: 0.8519 - val_loss: 0.8491 - val_acc: 0.6667\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6706 - acc: 0.8519 - val_loss: 0.8421 - val_acc: 0.7333\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6657 - acc: 0.8519 - val_loss: 0.8358 - val_acc: 0.7333\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.6612 - acc: 0.8519 - val_loss: 0.8299 - val_acc: 0.7333\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 304us/step - loss: 0.6570 - acc: 0.8519 - val_loss: 0.8240 - val_acc: 0.7333\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6530 - acc: 0.8667 - val_loss: 0.8182 - val_acc: 0.7333\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.6488 - acc: 0.8667 - val_loss: 0.8127 - val_acc: 0.7333\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 304us/step - loss: 0.6450 - acc: 0.8667 - val_loss: 0.8074 - val_acc: 0.7333\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 548us/step - loss: 0.6417 - acc: 0.8667 - val_loss: 0.8025 - val_acc: 0.7333\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.6381 - acc: 0.8667 - val_loss: 0.7977 - val_acc: 0.7333\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 304us/step - loss: 0.6348 - acc: 0.8667 - val_loss: 0.7926 - val_acc: 0.7333\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.6315 - acc: 0.8593 - val_loss: 0.7877 - val_acc: 0.7333\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 304us/step - loss: 0.6283 - acc: 0.8444 - val_loss: 0.7836 - val_acc: 0.7333\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6253 - acc: 0.8519 - val_loss: 0.7795 - val_acc: 0.7333\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 311us/step - loss: 0.6225 - acc: 0.8444 - val_loss: 0.7756 - val_acc: 0.7333\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 348us/step - loss: 0.6197 - acc: 0.8444 - val_loss: 0.7716 - val_acc: 0.7333\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6170 - acc: 0.8444 - val_loss: 0.7679 - val_acc: 0.7333\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 348us/step - loss: 0.6145 - acc: 0.8444 - val_loss: 0.7641 - val_acc: 0.7333\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.6119 - acc: 0.8444 - val_loss: 0.7604 - val_acc: 0.7333\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.6094 - acc: 0.8370 - val_loss: 0.7571 - val_acc: 0.7333\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6071 - acc: 0.8444 - val_loss: 0.7539 - val_acc: 0.7333\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 289us/step - loss: 0.6048 - acc: 0.8444 - val_loss: 0.7508 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 9 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 1.5348 - acc: 0.2000 - val_loss: 1.4735 - val_acc: 0.3333\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 1.4069 - acc: 0.2519 - val_loss: 1.3446 - val_acc: 0.4000\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 1.3009 - acc: 0.3407 - val_loss: 1.2341 - val_acc: 0.4000\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 289us/step - loss: 1.2115 - acc: 0.4370 - val_loss: 1.1411 - val_acc: 0.4667\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 1.1354 - acc: 0.5704 - val_loss: 1.0610 - val_acc: 0.6667\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 215us/step - loss: 1.0706 - acc: 0.6667 - val_loss: 0.9966 - val_acc: 0.6667\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 1.0188 - acc: 0.7259 - val_loss: 0.9402 - val_acc: 0.8667\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.9729 - acc: 0.7630 - val_loss: 0.8950 - val_acc: 0.8667\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.9357 - acc: 0.7926 - val_loss: 0.8566 - val_acc: 0.8667\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.9044 - acc: 0.8074 - val_loss: 0.8235 - val_acc: 0.8667\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8768 - acc: 0.8074 - val_loss: 0.7957 - val_acc: 0.8667\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.8535 - acc: 0.8074 - val_loss: 0.7716 - val_acc: 0.8667\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.8325 - acc: 0.8074 - val_loss: 0.7504 - val_acc: 0.8667\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.8144 - acc: 0.8074 - val_loss: 0.7314 - val_acc: 0.8667\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.7981 - acc: 0.8074 - val_loss: 0.7155 - val_acc: 0.8667\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.7839 - acc: 0.8074 - val_loss: 0.7010 - val_acc: 0.8667\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.7711 - acc: 0.8074 - val_loss: 0.6881 - val_acc: 0.8667\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7595 - acc: 0.8000 - val_loss: 0.6764 - val_acc: 0.8667\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.7489 - acc: 0.8000 - val_loss: 0.6660 - val_acc: 0.8667\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.7394 - acc: 0.8074 - val_loss: 0.6564 - val_acc: 0.8667\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7305 - acc: 0.8074 - val_loss: 0.6482 - val_acc: 0.8667\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.7225 - acc: 0.8074 - val_loss: 0.6406 - val_acc: 0.8667\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 289us/step - loss: 0.7151 - acc: 0.8148 - val_loss: 0.6330 - val_acc: 0.8667\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7082 - acc: 0.8074 - val_loss: 0.6265 - val_acc: 0.8667\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 281us/step - loss: 0.7018 - acc: 0.8148 - val_loss: 0.6206 - val_acc: 0.8667\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6956 - acc: 0.8222 - val_loss: 0.6148 - val_acc: 0.8667\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 215us/step - loss: 0.6898 - acc: 0.8222 - val_loss: 0.6091 - val_acc: 0.8667\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 257us/step - loss: 0.6845 - acc: 0.8222 - val_loss: 0.6035 - val_acc: 0.8667\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.6793 - acc: 0.8222 - val_loss: 0.5986 - val_acc: 0.8667\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6747 - acc: 0.8222 - val_loss: 0.5939 - val_acc: 0.8667\n",
      "Running Fold 10 / 10\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.7888 - acc: 0.7407 - val_loss: 0.6958 - val_acc: 0.8667\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.7752 - acc: 0.7556 - val_loss: 0.6840 - val_acc: 0.8667\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.7629 - acc: 0.7556 - val_loss: 0.6730 - val_acc: 0.8667\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.7513 - acc: 0.7778 - val_loss: 0.6632 - val_acc: 0.8667\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.7411 - acc: 0.7778 - val_loss: 0.6544 - val_acc: 0.9333\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 0s 267us/step - loss: 0.7318 - acc: 0.7926 - val_loss: 0.6463 - val_acc: 0.9333\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 0s 230us/step - loss: 0.7232 - acc: 0.8074 - val_loss: 0.6388 - val_acc: 0.9333\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.7148 - acc: 0.8148 - val_loss: 0.6320 - val_acc: 0.9333\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 0s 289us/step - loss: 0.7072 - acc: 0.8222 - val_loss: 0.6259 - val_acc: 0.9333\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.7004 - acc: 0.8222 - val_loss: 0.6203 - val_acc: 0.9333\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6943 - acc: 0.8222 - val_loss: 0.6148 - val_acc: 0.9333\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.6885 - acc: 0.8222 - val_loss: 0.6097 - val_acc: 0.9333\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.6833 - acc: 0.8296 - val_loss: 0.6046 - val_acc: 0.9333\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.6778 - acc: 0.8296 - val_loss: 0.6001 - val_acc: 0.9333\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6731 - acc: 0.8370 - val_loss: 0.5960 - val_acc: 0.9333\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6685 - acc: 0.8370 - val_loss: 0.5921 - val_acc: 0.9333\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6638 - acc: 0.8296 - val_loss: 0.5881 - val_acc: 0.9333\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 0s 229us/step - loss: 0.6595 - acc: 0.8370 - val_loss: 0.5845 - val_acc: 0.9333\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6558 - acc: 0.8370 - val_loss: 0.5816 - val_acc: 0.9333\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 0s 304us/step - loss: 0.6524 - acc: 0.8370 - val_loss: 0.5784 - val_acc: 0.9333\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 0s 244us/step - loss: 0.6488 - acc: 0.8444 - val_loss: 0.5752 - val_acc: 0.9333\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6453 - acc: 0.8444 - val_loss: 0.5726 - val_acc: 0.9333\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6420 - acc: 0.8370 - val_loss: 0.5697 - val_acc: 0.9333\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.6388 - acc: 0.8370 - val_loss: 0.5667 - val_acc: 0.9333\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6358 - acc: 0.8370 - val_loss: 0.5642 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 0s 259us/step - loss: 0.6328 - acc: 0.8370 - val_loss: 0.5617 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 0s 237us/step - loss: 0.6299 - acc: 0.8370 - val_loss: 0.5591 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 0s 222us/step - loss: 0.6274 - acc: 0.8370 - val_loss: 0.5567 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 0s 252us/step - loss: 0.6247 - acc: 0.8370 - val_loss: 0.5544 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 0s 274us/step - loss: 0.6223 - acc: 0.8370 - val_loss: 0.5521 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "\n",
    "labels = y\n",
    "data = x\n",
    "\n",
    "labels = np_utils.to_categorical(labels, nb_classes) \n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "avg_acc = 0\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "i=0\n",
    "\n",
    "for train, test in skf.split(x,y):\n",
    "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    i+=1\n",
    "    model = None # Clearing the NN.\n",
    "    model = build_logistic_model(input_dim, nb_classes)\n",
    "    \n",
    "    std = np.std(data[train],0)\n",
    "    mean = np.mean(data[train],0)\n",
    "    \n",
    "    x_train = (data[train]-mean)/std\n",
    "    x_test = (data[test] - mean)/std        \n",
    "    \n",
    "    avg_acc += train_and_evaluate_model(model, x_train, labels[train], x_test, labels[test])\n",
    "    \n",
    "    # Predict the values from the validation dataset\n",
    "    Y_pred = model.predict(x_test)\n",
    "    # Convert predictions classes to one hot vectors \n",
    "    Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "    # Convert validation observations to one hot vectors\n",
    "    Y_true = np.argmax(labels[test],axis = 1) \n",
    "    \n",
    "    y_true.extend(Y_true)\n",
    "    y_pred.extend(Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:  0.8333333432674408\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Accuracy: \", avg_acc/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(np.array(y_true), np.array(y_pred)) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(3)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
