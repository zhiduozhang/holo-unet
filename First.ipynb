{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import fnmatch\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data\\\\unlabelled\"\n",
    "sz=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.20 s.tifheightmap.mat',\n",
       " '0.78 s.tifheightmap.mat',\n",
       " '0.79 s.tifheightmap.mat',\n",
       " '0.80 s.tifheightmap.mat',\n",
       " '12.59 s.tifheightmap.mat',\n",
       " '12.60 s.tifheightmap.mat',\n",
       " '14.80 s.tifheightmap.mat',\n",
       " '16.80 s.tifheightmap.mat',\n",
       " '19.60 s.tifheightmap.mat',\n",
       " '22.00 s.tifheightmap.mat',\n",
       " '27.00 s.tifheightmap.mat',\n",
       " '28.79 s.tifheightmap.mat',\n",
       " '30.00 s.tifheightmap.mat',\n",
       " '32.00 s.tifheightmap.mat',\n",
       " '33.40 s.tifheightmap.mat',\n",
       " '36.19 s.tifheightmap.mat',\n",
       " '36.20 s.tifheightmap.mat',\n",
       " '38.20 s.tifheightmap.mat',\n",
       " '43.40 s.tifheightmap.mat',\n",
       " '44.60 s.tifheightmap.mat',\n",
       " '47.59 s.tifheightmap.mat',\n",
       " '47.60 s.tifheightmap.mat',\n",
       " '51.80 s.tifheightmap.mat',\n",
       " '52.60 s.tifheightmap.mat',\n",
       " '53.60 s.tifheightmap.mat',\n",
       " '54.40 s.tifheightmap.mat',\n",
       " '55.00 s.tifheightmap.mat',\n",
       " '56.00 s.tifheightmap.mat',\n",
       " '56.59 s.tifheightmap.mat',\n",
       " '57.00 s.tifheightmap.mat',\n",
       " '59.60 s.tifheightmap.mat',\n",
       " '6.80 s.tifheightmap.mat',\n",
       " '8.78 s.tifheightmap.mat',\n",
       " '8.79 s.tifheightmap.mat',\n",
       " '8.80 s.tifheightmap.mat',\n",
       " 'ids.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584\n",
      "368\n",
      "(35, 584, 368)\n",
      "[[0.29372 0.34945 0.38375 ... 0.      0.      0.     ]\n",
      " [0.34831 0.41226 0.45008 ... 0.      0.      0.     ]\n",
      " [0.39016 0.45942 0.49873 ... 0.      0.      0.     ]\n",
      " ...\n",
      " [0.      0.      0.      ... 0.24495 0.20439 0.15776]\n",
      " [0.      0.      0.      ... 0.2131  0.1794  0.13998]\n",
      " [0.      0.      0.      ... 0.17431 0.14779 0.11631]]\n",
      "[[0.29372 0.34945 0.38375 ... 0.      0.      0.     ]\n",
      " [0.34831 0.41226 0.45008 ... 0.      0.      0.     ]\n",
      " [0.39016 0.45942 0.49873 ... 0.      0.      0.     ]\n",
      " ...\n",
      " [0.      0.      0.      ... 0.      0.      0.     ]\n",
      " [0.      0.      0.      ... 0.      0.      0.     ]\n",
      " [0.      0.      0.      ... 0.      0.      0.     ]]\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "\n",
    "x = 0\n",
    "y = 368\n",
    "\n",
    "filenames = []\n",
    "hm_list = []\n",
    "\n",
    "for file in os.listdir(PATH):\n",
    "    if fnmatch.fnmatch(file, '*.mat'):\n",
    "        files.append(file)\n",
    "        hm = sio.loadmat(f'{PATH}\\\\{file}')['height_r']\n",
    "        # print(hm.shape[0])\n",
    "        hm_list.append(hm)\n",
    "        filenames.append(file)\n",
    "        \n",
    "        x=max(hm.shape[0],x)\n",
    "        y=max(hm.shape[1],y)\n",
    "        \n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "hm_array = []\n",
    "\n",
    "for m in hm_list:\n",
    "    hm = np.pad(np.copy(m), ((0,x-m.shape[0]),(0,y-m.shape[1])), 'constant', constant_values=(0))\n",
    "    hm_array.append(hm)\n",
    "\n",
    "df = pd.DataFrame(hm_list[0])\n",
    "df.to_csv(\"hm.csv\")    \n",
    "\n",
    "df = pd.DataFrame(hm_np[0,:,:])\n",
    "df.to_csv(\"hm_np.csv\")\n",
    "\n",
    "hm_np = np.array(hm_array)\n",
    "print(hm_np.shape)\n",
    "print(hm_list[0])\n",
    "print(hm_np[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img = plt.imread(f'{PATH}\\\\{files[0]}')\n",
    "# plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = sio.loadmat(f'{PATH}\\\\{files[0]}')['height_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29372, 0.34945, 0.38375, ..., 0.     , 0.     , 0.     ],\n",
       "       [0.34831, 0.41226, 0.45008, ..., 0.     , 0.     , 0.     ],\n",
       "       [0.39016, 0.45942, 0.49873, ..., 0.     , 0.     , 0.     ],\n",
       "       ...,\n",
       "       [0.     , 0.     , 0.     , ..., 0.24495, 0.20439, 0.15776],\n",
       "       [0.     , 0.     , 0.     , ..., 0.2131 , 0.1794 , 0.13998],\n",
       "       [0.     , 0.     , 0.     , ..., 0.17431, 0.14779, 0.11631]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "# Input and target placeholders\n",
    "inputs_ = tf.placeholder(tf.float32, (None, x,y,1), name=\"input\")\n",
    "targets_ = tf.placeholder(tf.float32, (None, x,y,1), name=\"target\")\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs=inputs_, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 584x368x16\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, pool_size=(2,2), strides=(2,2), padding='same')\n",
    "# Now 292x184x16\n",
    "conv2 = tf.layers.conv2d(inputs=maxpool1, filters=8, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 292x184x8\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, pool_size=(2,2), strides=(2,2), padding='same')\n",
    "# Now 146x92x8\n",
    "conv3 = tf.layers.conv2d(inputs=maxpool2, filters=8, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 146x92x8\n",
    "encoded = tf.layers.max_pooling2d(conv3, pool_size=(2,2), strides=(2,2), padding='same')\n",
    "# Now 73x46x8\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_images(encoded, size=(146,92), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 7x7x8\n",
    "conv4 = tf.layers.conv2d(inputs=upsample1, filters=8, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "upsample2 = tf.image.resize_images(conv4, size=(292,184), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 14x14x8\n",
    "conv5 = tf.layers.conv2d(inputs=upsample2, filters=8, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "upsample3 = tf.image.resize_images(conv5, size=(584,368), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# Now 28x28x8\n",
    "conv6 = tf.layers.conv2d(inputs=upsample3, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "\n",
    "logits = tf.layers.conv2d(inputs=conv6, filters=1, kernel_size=(3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "decoded = tf.nn.sigmoid(logits)\n",
    "\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "\n",
    "# Get cost and define the optimizer\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-acc24857a883>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# imgs = batch[0].reshape((-1, x, y, 1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: imgs,\n\u001b[1;32m---> 15\u001b[1;33m                                                          targets_: imgs})\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1086\u001b[1;33m             raise TypeError('The value of a feed cannot be a tf.Tensor object. '\n\u001b[0m\u001b[0;32m   1087\u001b[0m                             \u001b[1;34m'Acceptable feed values include Python scalars, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m                             'strings, lists, numpy ndarrays, or TensorHandles.')\n",
      "\u001b[1;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles."
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 5\n",
    "shuffle_size = 1000\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices(hm_np).shuffle(shuffle_size).batch(batch_size).repeat()\n",
    "\n",
    "iterator = ds.make_one_shot_iterator()\n",
    "imgs = iterator.get_next()\n",
    "\n",
    "for e in range(epochs):\n",
    "    for ii in range(hm_np.shape[0]//batch_size):\n",
    "        # imgs = batch[0].reshape((-1, x, y, 1))\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
