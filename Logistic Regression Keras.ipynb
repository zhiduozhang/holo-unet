{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment\n",
    "# experiment = Experiment(api_key=\"xktj4EX0zB8YcQ3BEaFwOQYpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duo\\Anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\train\\\\\"\n",
    "train_csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\train\\\\ids.csv\"\n",
    "test_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\test\\\\\"\n",
    "test_csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\test\\\\ids.csv\"\n",
    "\n",
    "dest_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\\"\n",
    "\n",
    "csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\ids.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv,index_col=0).sample(frac=1)\n",
    "\n",
    "df['log_volume'] = df['volume'].apply(np.log)\n",
    "\n",
    "x = df.drop(columns=['name','date','flow_rate','source','moments','inertia_tensor'])\n",
    "# x = standardize = preprocessing.scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>flow_rate</th>\n",
       "      <th>source</th>\n",
       "      <th>peak_val</th>\n",
       "      <th>area</th>\n",
       "      <th>volume</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>euler_number</th>\n",
       "      <th>extent</th>\n",
       "      <th>mean_intensity</th>\n",
       "      <th>moments</th>\n",
       "      <th>orientation</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>inertia_tensor</th>\n",
       "      <th>cluster</th>\n",
       "      <th>num_peaks</th>\n",
       "      <th>log_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>2017.11.22</td>\n",
       "      <td>7200</td>\n",
       "      <td>35.80 s.tifheightmap.mat</td>\n",
       "      <td>4.854192</td>\n",
       "      <td>2055</td>\n",
       "      <td>5440.452402</td>\n",
       "      <td>0.946396</td>\n",
       "      <td>1</td>\n",
       "      <td>0.368544</td>\n",
       "      <td>2.647422</td>\n",
       "      <td>[[2.05500000e+03 9.37710000e+04 5.11496900e+06...</td>\n",
       "      <td>0.886416</td>\n",
       "      <td>236.835570</td>\n",
       "      <td>[[292.97894613 278.03612482]\\r\\n [278.03612482...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.601617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2017.11.17</td>\n",
       "      <td>3600</td>\n",
       "      <td>1.25 s.tifheightmap.mat</td>\n",
       "      <td>8.839536</td>\n",
       "      <td>1234</td>\n",
       "      <td>6886.017413</td>\n",
       "      <td>0.489669</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>5.544297</td>\n",
       "      <td>[[1.24200000e+03 3.03310000e+04 8.91325000e+05...</td>\n",
       "      <td>1.298008</td>\n",
       "      <td>144.953319</td>\n",
       "      <td>[[ 95.96786714   7.6775466 ]\\r\\n [  7.6775466 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.837248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12_flipped</td>\n",
       "      <td>2017.11.09</td>\n",
       "      <td>3600</td>\n",
       "      <td>chip3_03heightmap.mat</td>\n",
       "      <td>12.532234</td>\n",
       "      <td>4756</td>\n",
       "      <td>38034.038483</td>\n",
       "      <td>0.756339</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717995</td>\n",
       "      <td>7.997064</td>\n",
       "      <td>[[4.75600000e+03 2.31341000e+05 1.38869750e+07...</td>\n",
       "      <td>1.199091</td>\n",
       "      <td>292.693434</td>\n",
       "      <td>[[301.57312913 115.9663349 ]\\r\\n [115.9663349 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.546237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>84_flipped</td>\n",
       "      <td>2017.11.22</td>\n",
       "      <td>1800</td>\n",
       "      <td>44.60 s.tifheightmap.mat</td>\n",
       "      <td>21.427335</td>\n",
       "      <td>2675</td>\n",
       "      <td>23258.006678</td>\n",
       "      <td>0.921300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422992</td>\n",
       "      <td>8.694582</td>\n",
       "      <td>[[2.67500000e+03 1.34857000e+05 8.05168900e+06...</td>\n",
       "      <td>-0.940939</td>\n",
       "      <td>291.279221</td>\n",
       "      <td>[[ 295.92398288 -268.25541305]\\r\\n [-268.25541...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.054405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>2017.11.17</td>\n",
       "      <td>3600</td>\n",
       "      <td>26.45 s.tifheightmap.mat</td>\n",
       "      <td>4.989847</td>\n",
       "      <td>5936</td>\n",
       "      <td>16831.576998</td>\n",
       "      <td>0.972562</td>\n",
       "      <td>1</td>\n",
       "      <td>0.346972</td>\n",
       "      <td>2.835508</td>\n",
       "      <td>[[5.93600000e+03 6.72046000e+05 9.04600940e+07...</td>\n",
       "      <td>1.213680</td>\n",
       "      <td>497.244733</td>\n",
       "      <td>[[ 464.67299942  848.21577169]\\r\\n [ 848.21577...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.731012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name        date  flow_rate                    source   peak_val  \\\n",
       "120         120  2017.11.22       7200  35.80 s.tifheightmap.mat   4.854192   \n",
       "32           32  2017.11.17       3600   1.25 s.tifheightmap.mat   8.839536   \n",
       "225  12_flipped  2017.11.09       3600     chip3_03heightmap.mat  12.532234   \n",
       "385  84_flipped  2017.11.22       1800  44.60 s.tifheightmap.mat  21.427335   \n",
       "47           47  2017.11.17       3600  26.45 s.tifheightmap.mat   4.989847   \n",
       "\n",
       "     area        volume  eccentricity  euler_number    extent  mean_intensity  \\\n",
       "120  2055   5440.452402      0.946396             1  0.368544        2.647422   \n",
       "32   1234   6886.017413      0.489669             1  0.624434        5.544297   \n",
       "225  4756  38034.038483      0.756339             1  0.717995        7.997064   \n",
       "385  2675  23258.006678      0.921300             1  0.422992        8.694582   \n",
       "47   5936  16831.576998      0.972562             1  0.346972        2.835508   \n",
       "\n",
       "                                               moments  orientation  \\\n",
       "120  [[2.05500000e+03 9.37710000e+04 5.11496900e+06...     0.886416   \n",
       "32   [[1.24200000e+03 3.03310000e+04 8.91325000e+05...     1.298008   \n",
       "225  [[4.75600000e+03 2.31341000e+05 1.38869750e+07...     1.199091   \n",
       "385  [[2.67500000e+03 1.34857000e+05 8.05168900e+06...    -0.940939   \n",
       "47   [[5.93600000e+03 6.72046000e+05 9.04600940e+07...     1.213680   \n",
       "\n",
       "      perimeter                                     inertia_tensor  cluster  \\\n",
       "120  236.835570  [[292.97894613 278.03612482]\\r\\n [278.03612482...        2   \n",
       "32   144.953319  [[ 95.96786714   7.6775466 ]\\r\\n [  7.6775466 ...        0   \n",
       "225  292.693434  [[301.57312913 115.9663349 ]\\r\\n [115.9663349 ...        0   \n",
       "385  291.279221  [[ 295.92398288 -268.25541305]\\r\\n [-268.25541...        0   \n",
       "47   497.244733  [[ 464.67299942  848.21577169]\\r\\n [ 848.21577...        2   \n",
       "\n",
       "     num_peaks  log_volume  \n",
       "120          1    8.601617  \n",
       "32           1    8.837248  \n",
       "225          1   10.546237  \n",
       "385          1   10.054405  \n",
       "47           1    9.731012  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(df.shape[0]/10)\n",
    "\n",
    "x_test = np.array(x[:test_size])\n",
    "y_test = df['flow_rate'][:test_size].values\n",
    "\n",
    "x_train = np.array(x[test_size:])\n",
    "y_train = df['flow_rate'][test_size:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0 ...   0   0 106]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ...,  0,  0, 10], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.bincount(y_train))\n",
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 3\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 1800] = 0\n",
    "y_train[y_train == 3600] = 1\n",
    "y_train[y_train == 7200] = 2\n",
    "\n",
    "y_test[y_test == 1800] = 0\n",
    "y_test[y_test == 3600] = 1\n",
    "y_test[y_test == 7200] = 2\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes) \n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmda = 0.01\n",
    "\n",
    "def build_logistic_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim, input_dim=input_dim,\n",
    "                    kernel_regularizer=l2(lmda),\n",
    "                    activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = build_logistic_model(input_dim, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 362 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "362/362 [==============================] - 4s 10ms/step - loss: 1.3396 - acc: 0.3674 - val_loss: 1.3562 - val_acc: 0.3250\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 0s 319us/step - loss: 1.2704 - acc: 0.3840 - val_loss: 1.3101 - val_acc: 0.3500\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 0s 449us/step - loss: 1.2233 - acc: 0.4006 - val_loss: 1.2745 - val_acc: 0.3500\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 0s 230us/step - loss: 1.1894 - acc: 0.3923 - val_loss: 1.2467 - val_acc: 0.3250\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 0s 276us/step - loss: 1.1643 - acc: 0.3812 - val_loss: 1.2251 - val_acc: 0.3250\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 0s 380us/step - loss: 1.1453 - acc: 0.3757 - val_loss: 1.2080 - val_acc: 0.3250\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 0s 319us/step - loss: 1.1315 - acc: 0.3867 - val_loss: 1.1938 - val_acc: 0.3250\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 0s 277us/step - loss: 1.1195 - acc: 0.3840 - val_loss: 1.1817 - val_acc: 0.3250\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 0s 406us/step - loss: 1.1098 - acc: 0.3950 - val_loss: 1.1718 - val_acc: 0.3250\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 0s 276us/step - loss: 1.1017 - acc: 0.3923 - val_loss: 1.1632 - val_acc: 0.3500\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 0s 329us/step - loss: 1.0950 - acc: 0.3950 - val_loss: 1.1559 - val_acc: 0.4250\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 0s 281us/step - loss: 1.0888 - acc: 0.4033 - val_loss: 1.1507 - val_acc: 0.4250\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 0s 320us/step - loss: 1.0836 - acc: 0.4033 - val_loss: 1.1454 - val_acc: 0.4250\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 0s 319us/step - loss: 1.0793 - acc: 0.4033 - val_loss: 1.1412 - val_acc: 0.4250\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 0s 320us/step - loss: 1.0755 - acc: 0.4116 - val_loss: 1.1372 - val_acc: 0.4250\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 0s 362us/step - loss: 1.0726 - acc: 0.4033 - val_loss: 1.1334 - val_acc: 0.4250\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 0s 424us/step - loss: 1.0688 - acc: 0.4171 - val_loss: 1.1291 - val_acc: 0.4250\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 0s 458us/step - loss: 1.0652 - acc: 0.4171 - val_loss: 1.1261 - val_acc: 0.4250\n",
      "Epoch 19/20\n",
      "362/362 [==============================] - 0s 545us/step - loss: 1.0632 - acc: 0.4088 - val_loss: 1.1234 - val_acc: 0.4250\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 0s 285us/step - loss: 1.0604 - acc: 0.4116 - val_loss: 1.1211 - val_acc: 0.4250\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.1210774540901185\n",
      "Test accuracy: 0.425\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 3\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 10\n",
      "Train on 360 samples, validate on 42 samples\n",
      "Epoch 1/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 1.5389 - acc: 0.3000 - val_loss: 1.4301 - val_acc: 0.3333\n",
      "Epoch 2/20\n",
      "360/360 [==============================] - 0s 374us/step - loss: 1.4472 - acc: 0.3028 - val_loss: 1.3968 - val_acc: 0.3571\n",
      "Epoch 3/20\n",
      "360/360 [==============================] - 0s 367us/step - loss: 1.3776 - acc: 0.3111 - val_loss: 1.3705 - val_acc: 0.3095\n",
      "Epoch 4/20\n",
      "360/360 [==============================] - 0s 360us/step - loss: 1.3300 - acc: 0.3056 - val_loss: 1.3479 - val_acc: 0.2857\n",
      "Epoch 5/20\n",
      "360/360 [==============================] - 0s 384us/step - loss: 1.2938 - acc: 0.3222 - val_loss: 1.3243 - val_acc: 0.2857\n",
      "Epoch 6/20\n",
      "360/360 [==============================] - 0s 256us/step - loss: 1.2653 - acc: 0.3278 - val_loss: 1.3044 - val_acc: 0.2619\n",
      "Epoch 7/20\n",
      "360/360 [==============================] - 0s 284us/step - loss: 1.2420 - acc: 0.3278 - val_loss: 1.2838 - val_acc: 0.2619\n",
      "Epoch 8/20\n",
      "360/360 [==============================] - 0s 264us/step - loss: 1.2228 - acc: 0.3194 - val_loss: 1.2648 - val_acc: 0.2619\n",
      "Epoch 9/20\n",
      "360/360 [==============================] - 0s 267us/step - loss: 1.2056 - acc: 0.3278 - val_loss: 1.2477 - val_acc: 0.2619\n",
      "Epoch 10/20\n",
      "360/360 [==============================] - 0s 264us/step - loss: 1.1906 - acc: 0.3361 - val_loss: 1.2314 - val_acc: 0.2619\n",
      "Epoch 11/20\n",
      "360/360 [==============================] - 0s 265us/step - loss: 1.1773 - acc: 0.3556 - val_loss: 1.2153 - val_acc: 0.2619\n",
      "Epoch 12/20\n",
      "360/360 [==============================] - 0s 285us/step - loss: 1.1657 - acc: 0.3639 - val_loss: 1.2022 - val_acc: 0.2857\n",
      "Epoch 13/20\n",
      "360/360 [==============================] - 0s 285us/step - loss: 1.1552 - acc: 0.3722 - val_loss: 1.1895 - val_acc: 0.2857\n",
      "Epoch 14/20\n",
      "360/360 [==============================] - 0s 263us/step - loss: 1.1465 - acc: 0.3639 - val_loss: 1.1785 - val_acc: 0.3333\n",
      "Epoch 15/20\n",
      "360/360 [==============================] - 0s 278us/step - loss: 1.1386 - acc: 0.3722 - val_loss: 1.1699 - val_acc: 0.3333\n",
      "Epoch 16/20\n",
      "360/360 [==============================] - 0s 267us/step - loss: 1.1308 - acc: 0.3833 - val_loss: 1.1623 - val_acc: 0.3333\n",
      "Epoch 17/20\n",
      "360/360 [==============================] - 0s 268us/step - loss: 1.1245 - acc: 0.3806 - val_loss: 1.1508 - val_acc: 0.3333\n",
      "Epoch 18/20\n",
      "360/360 [==============================] - 0s 286us/step - loss: 1.1186 - acc: 0.3889 - val_loss: 1.1433 - val_acc: 0.3333\n",
      "Epoch 19/20\n",
      "360/360 [==============================] - 0s 285us/step - loss: 1.1131 - acc: 0.4083 - val_loss: 1.1329 - val_acc: 0.3095\n",
      "Epoch 20/20\n",
      "360/360 [==============================] - 0s 261us/step - loss: 1.1081 - acc: 0.3889 - val_loss: 1.1261 - val_acc: 0.3095\n",
      "Running Fold 2 / 10\n",
      "Train on 360 samples, validate on 42 samples\n",
      "Epoch 1/20\n",
      "360/360 [==============================] - 0s 1ms/step - loss: 1.5062 - acc: 0.3028 - val_loss: 1.3480 - val_acc: 0.3095\n",
      "Epoch 2/20\n",
      "360/360 [==============================] - 0s 270us/step - loss: 1.4147 - acc: 0.3028 - val_loss: 1.2750 - val_acc: 0.2857\n",
      "Epoch 3/20\n",
      "360/360 [==============================] - 0s 267us/step - loss: 1.3442 - acc: 0.3056 - val_loss: 1.2190 - val_acc: 0.2857\n",
      "Epoch 4/20\n",
      "360/360 [==============================] - 0s 253us/step - loss: 1.2897 - acc: 0.3222 - val_loss: 1.1791 - val_acc: 0.3333\n",
      "Epoch 5/20\n",
      "360/360 [==============================] - 0s 286us/step - loss: 1.2491 - acc: 0.3222 - val_loss: 1.1446 - val_acc: 0.3571\n",
      "Epoch 6/20\n",
      "360/360 [==============================] - 0s 272us/step - loss: 1.2169 - acc: 0.3278 - val_loss: 1.1212 - val_acc: 0.3571\n",
      "Epoch 7/20\n",
      "360/360 [==============================] - 0s 249us/step - loss: 1.1927 - acc: 0.3222 - val_loss: 1.1030 - val_acc: 0.3810\n",
      "Epoch 8/20\n",
      "360/360 [==============================] - 0s 281us/step - loss: 1.1730 - acc: 0.3361 - val_loss: 1.0879 - val_acc: 0.3810\n",
      "Epoch 9/20\n",
      "360/360 [==============================] - 0s 257us/step - loss: 1.1565 - acc: 0.3361 - val_loss: 1.0770 - val_acc: 0.3810\n",
      "Epoch 10/20\n",
      "360/360 [==============================] - 0s 274us/step - loss: 1.1429 - acc: 0.3639 - val_loss: 1.0672 - val_acc: 0.3810\n",
      "Epoch 11/20\n",
      "360/360 [==============================] - 0s 295us/step - loss: 1.1325 - acc: 0.3694 - val_loss: 1.0594 - val_acc: 0.3810\n",
      "Epoch 12/20\n",
      "360/360 [==============================] - 0s 306us/step - loss: 1.1231 - acc: 0.3778 - val_loss: 1.0535 - val_acc: 0.3810\n",
      "Epoch 13/20\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.1295 - acc: 0.366 - 0s 247us/step - loss: 1.1152 - acc: 0.3833 - val_loss: 1.0490 - val_acc: 0.3810\n",
      "Epoch 14/20\n",
      "360/360 [==============================] - 0s 253us/step - loss: 1.1085 - acc: 0.3861 - val_loss: 1.0448 - val_acc: 0.3810\n",
      "Epoch 15/20\n",
      "360/360 [==============================] - 0s 282us/step - loss: 1.1029 - acc: 0.3944 - val_loss: 1.0417 - val_acc: 0.3810\n",
      "Epoch 16/20\n",
      "360/360 [==============================] - 0s 260us/step - loss: 1.0979 - acc: 0.3833 - val_loss: 1.0397 - val_acc: 0.3810\n",
      "Epoch 17/20\n",
      "360/360 [==============================] - 0s 277us/step - loss: 1.0937 - acc: 0.3944 - val_loss: 1.0370 - val_acc: 0.4048\n",
      "Epoch 18/20\n",
      "360/360 [==============================] - 0s 281us/step - loss: 1.0897 - acc: 0.3972 - val_loss: 1.0359 - val_acc: 0.4048\n",
      "Epoch 19/20\n",
      "360/360 [==============================] - 0s 310us/step - loss: 1.0864 - acc: 0.4167 - val_loss: 1.0351 - val_acc: 0.3810\n",
      "Epoch 20/20\n",
      "360/360 [==============================] - 0s 272us/step - loss: 1.0831 - acc: 0.4139 - val_loss: 1.0345 - val_acc: 0.3810\n",
      "Running Fold 3 / 10\n",
      "Train on 361 samples, validate on 41 samples\n",
      "Epoch 1/20\n",
      "361/361 [==============================] - 0s 1ms/step - loss: 1.6947 - acc: 0.3130 - val_loss: 1.5051 - val_acc: 0.3171\n",
      "Epoch 2/20\n",
      "361/361 [==============================] - 0s 255us/step - loss: 1.5611 - acc: 0.3269 - val_loss: 1.4251 - val_acc: 0.3171\n",
      "Epoch 3/20\n",
      "361/361 [==============================] - 0s 280us/step - loss: 1.4531 - acc: 0.3158 - val_loss: 1.3660 - val_acc: 0.3415\n",
      "Epoch 4/20\n",
      "361/361 [==============================] - 0s 259us/step - loss: 1.3741 - acc: 0.3213 - val_loss: 1.3242 - val_acc: 0.3659\n",
      "Epoch 5/20\n",
      "361/361 [==============================] - 0s 279us/step - loss: 1.3137 - acc: 0.3186 - val_loss: 1.2926 - val_acc: 0.4146\n",
      "Epoch 6/20\n",
      "361/361 [==============================] - 0s 294us/step - loss: 1.2689 - acc: 0.3241 - val_loss: 1.2691 - val_acc: 0.3902\n",
      "Epoch 7/20\n",
      "361/361 [==============================] - 0s 259us/step - loss: 1.2342 - acc: 0.3324 - val_loss: 1.2496 - val_acc: 0.3659\n",
      "Epoch 8/20\n",
      "361/361 [==============================] - 0s 280us/step - loss: 1.2077 - acc: 0.3407 - val_loss: 1.2339 - val_acc: 0.4146\n",
      "Epoch 9/20\n",
      "361/361 [==============================] - 0s 262us/step - loss: 1.1866 - acc: 0.3601 - val_loss: 1.2203 - val_acc: 0.4146\n",
      "Epoch 10/20\n",
      "361/361 [==============================] - 0s 288us/step - loss: 1.1705 - acc: 0.3712 - val_loss: 1.2105 - val_acc: 0.3902\n",
      "Epoch 11/20\n",
      "361/361 [==============================] - 0s 295us/step - loss: 1.1574 - acc: 0.3684 - val_loss: 1.2009 - val_acc: 0.3902\n",
      "Epoch 12/20\n",
      "361/361 [==============================] - 0s 274us/step - loss: 1.1461 - acc: 0.3601 - val_loss: 1.1917 - val_acc: 0.3902\n",
      "Epoch 13/20\n",
      "361/361 [==============================] - 0s 277us/step - loss: 1.1360 - acc: 0.3767 - val_loss: 1.1835 - val_acc: 0.3902\n",
      "Epoch 14/20\n",
      "361/361 [==============================] - 0s 255us/step - loss: 1.1276 - acc: 0.3684 - val_loss: 1.1763 - val_acc: 0.3902\n",
      "Epoch 15/20\n",
      "361/361 [==============================] - 0s 287us/step - loss: 1.1198 - acc: 0.3629 - val_loss: 1.1707 - val_acc: 0.3415\n",
      "Epoch 16/20\n",
      "361/361 [==============================] - 0s 277us/step - loss: 1.1132 - acc: 0.3795 - val_loss: 1.1644 - val_acc: 0.3171\n",
      "Epoch 17/20\n",
      "361/361 [==============================] - 0s 287us/step - loss: 1.1069 - acc: 0.3767 - val_loss: 1.1597 - val_acc: 0.3415\n",
      "Epoch 18/20\n",
      "361/361 [==============================] - 0s 308us/step - loss: 1.1013 - acc: 0.3795 - val_loss: 1.1549 - val_acc: 0.3415\n",
      "Epoch 19/20\n",
      "361/361 [==============================] - 0s 269us/step - loss: 1.0967 - acc: 0.3878 - val_loss: 1.1503 - val_acc: 0.3415\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 279us/step - loss: 1.0918 - acc: 0.3878 - val_loss: 1.1462 - val_acc: 0.3415\n",
      "Running Fold 4 / 10\n",
      "Train on 361 samples, validate on 41 samples\n",
      "Epoch 1/20\n",
      "361/361 [==============================] - 0s 1ms/step - loss: 1.7001 - acc: 0.2825 - val_loss: 1.5579 - val_acc: 0.3659\n",
      "Epoch 2/20\n",
      "361/361 [==============================] - 0s 277us/step - loss: 1.5583 - acc: 0.2853 - val_loss: 1.4576 - val_acc: 0.3902\n",
      "Epoch 3/20\n",
      "361/361 [==============================] - 0s 270us/step - loss: 1.4449 - acc: 0.2798 - val_loss: 1.3825 - val_acc: 0.3902\n",
      "Epoch 4/20\n",
      "361/361 [==============================] - 0s 280us/step - loss: 1.3595 - acc: 0.2936 - val_loss: 1.3290 - val_acc: 0.4146\n",
      "Epoch 5/20\n",
      "361/361 [==============================] - 0s 295us/step - loss: 1.2973 - acc: 0.2909 - val_loss: 1.2901 - val_acc: 0.3902\n",
      "Epoch 6/20\n",
      "361/361 [==============================] - 0s 270us/step - loss: 1.2525 - acc: 0.3130 - val_loss: 1.2613 - val_acc: 0.3902\n",
      "Epoch 7/20\n",
      "361/361 [==============================] - 0s 269us/step - loss: 1.2202 - acc: 0.3352 - val_loss: 1.2400 - val_acc: 0.3659\n",
      "Epoch 8/20\n",
      "361/361 [==============================] - 0s 268us/step - loss: 1.1966 - acc: 0.3435 - val_loss: 1.2216 - val_acc: 0.3415\n",
      "Epoch 9/20\n",
      "361/361 [==============================] - 0s 277us/step - loss: 1.1788 - acc: 0.3518 - val_loss: 1.2070 - val_acc: 0.3415\n",
      "Epoch 10/20\n",
      "361/361 [==============================] - 0s 261us/step - loss: 1.1645 - acc: 0.3518 - val_loss: 1.1941 - val_acc: 0.3171\n",
      "Epoch 11/20\n",
      "361/361 [==============================] - 0s 288us/step - loss: 1.1526 - acc: 0.3546 - val_loss: 1.1817 - val_acc: 0.3171\n",
      "Epoch 12/20\n",
      "361/361 [==============================] - 0s 273us/step - loss: 1.1429 - acc: 0.3546 - val_loss: 1.1707 - val_acc: 0.3171\n",
      "Epoch 13/20\n",
      "361/361 [==============================] - 0s 258us/step - loss: 1.1339 - acc: 0.3601 - val_loss: 1.1605 - val_acc: 0.2927\n",
      "Epoch 14/20\n",
      "361/361 [==============================] - 0s 256us/step - loss: 1.1260 - acc: 0.3712 - val_loss: 1.1517 - val_acc: 0.2927\n",
      "Epoch 15/20\n",
      "361/361 [==============================] - 0s 254us/step - loss: 1.1199 - acc: 0.3629 - val_loss: 1.1444 - val_acc: 0.2927\n",
      "Epoch 16/20\n",
      "361/361 [==============================] - 0s 245us/step - loss: 1.1143 - acc: 0.3657 - val_loss: 1.1377 - val_acc: 0.3415\n",
      "Epoch 17/20\n",
      "361/361 [==============================] - 0s 254us/step - loss: 1.1089 - acc: 0.3740 - val_loss: 1.1312 - val_acc: 0.3415\n",
      "Epoch 18/20\n",
      "361/361 [==============================] - 0s 249us/step - loss: 1.1045 - acc: 0.3795 - val_loss: 1.1254 - val_acc: 0.3171\n",
      "Epoch 19/20\n",
      "361/361 [==============================] - 0s 266us/step - loss: 1.1007 - acc: 0.3823 - val_loss: 1.1201 - val_acc: 0.3659\n",
      "Epoch 20/20\n",
      "361/361 [==============================] - 0s 256us/step - loss: 1.0970 - acc: 0.3934 - val_loss: 1.1155 - val_acc: 0.3415\n",
      "Running Fold 5 / 10\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "\n",
    "labels = df['flow_rate'].values\n",
    "data = x\n",
    "\n",
    "labels[labels == 1800] = 0\n",
    "labels[labels == 3600] = 1\n",
    "labels[labels == 7200] = 2\n",
    "\n",
    "labels = np_utils.to_categorical(labels, nb_classes) \n",
    "\n",
    "skf = StratifiedKFold(df['flow_rate'].values, n_folds=n_folds, shuffle=True)\n",
    "avg_acc = 0\n",
    "\n",
    "for i, (train, test) in enumerate(skf):\n",
    "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    model = None # Clearing the NN.\n",
    "    model = build_logistic_model(input_dim, nb_classes)\n",
    "    \n",
    "    std = np.std(data[train],0)\n",
    "    mean = np.mean(data[train],0)\n",
    "    \n",
    "    x_train = (data[train]-mean)/std\n",
    "    x_test = (data[test] - mean)/std        \n",
    "    \n",
    "    avg_acc += train_and_evaluate_model(model, x_train, labels[train], x_test, labels[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Score: \", avg_acc/n_folds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
