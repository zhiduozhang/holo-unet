{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment\n",
    "# experiment = Experiment(api_key=\"xktj4EX0zB8YcQ3BEaFwOQYpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duo\\Anaconda3\\envs\\fastai\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\train\\\\\"\n",
    "train_csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\train\\\\ids.csv\"\n",
    "test_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\test\\\\\"\n",
    "test_csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\test\\\\ids.csv\"\n",
    "\n",
    "dest_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\\"\n",
    "\n",
    "csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\ids.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv,index_col=0).sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample to balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flow_rate\n",
      "1800    116\n",
      "3600    116\n",
      "7200    116\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ds_count = min(df.groupby('flow_rate').size())\n",
    "ds_flow = df.groupby('flow_rate').size().idxmin()\n",
    "\n",
    "samples = pd.concat([df[df['flow_rate']==i].sample(n=ds_count) for i in (1800,3600,7200)],ignore_index=True)\n",
    "\n",
    "df = samples.sample(frac=1)\n",
    "\n",
    "print(samples.groupby('flow_rate').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns which we aren't using as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df):\n",
    "    return df.drop(columns=['name','date','flow_rate','source','moments',\n",
    "                            'inertia_tensor','euler_number','num_peaks','cluster']).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_volume'] = df['volume'].apply(np.log)\n",
    "\n",
    "x = df.drop(columns=['name','date','flow_rate','source','moments','inertia_tensor'])\n",
    "\n",
    "# Drop catagorical features\n",
    "mat = x.drop(columns=['euler_number', 'num_peaks', 'cluster'])\n",
    "\n",
    "x = mat.as_matrix()\n",
    "# x = standardize = preprocessing.scale(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(df.shape[0]/10)\n",
    "\n",
    "x_test = np.array(x[:test_size])\n",
    "y_test = df['flow_rate'][:test_size].values\n",
    "\n",
    "x_train = np.array(x[test_size:])\n",
    "y_train = df['flow_rate'][test_size:].values\n",
    "\n",
    "std = np.std(x_train,0)\n",
    "mean = np.mean(x_train,0)\n",
    "    \n",
    "x_train = (x_train-mean)/std\n",
    "x_test = (x_test-mean)/std    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into balanced test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, 9)\n",
      "(30, 9)\n"
     ]
    }
   ],
   "source": [
    "x_test = pd.concat([df[df['flow_rate']==i].sample(n=10) for i in (1800,3600,7200)],ignore_index=True)\n",
    "y_test = x_test['flow_rate'].values\n",
    "\n",
    "x_train = pd.concat([df, x_test, x_test]).drop_duplicates(keep=False)\n",
    "y_train = x_train['flow_rate'].values\n",
    "\n",
    "x_test = drop_cols(x_test)\n",
    "x_train = drop_cols(x_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "std = np.std(x_train,0)\n",
    "mean = np.mean(x_train,0)\n",
    "    \n",
    "x_train = (x_train-mean)/std\n",
    "x_test = (x_test-mean)/std    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 3\n",
    "nb_epoch = 30\n",
    "\n",
    "lmda = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 1800] = 0\n",
    "y_train[y_train == 3600] = 1\n",
    "y_train[y_train == 7200] = 2\n",
    "\n",
    "y_test[y_test == 1800] = 0\n",
    "y_test[y_test == 3600] = 1\n",
    "y_test[y_test == 7200] = 2\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes) \n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logistic_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim, input_dim=input_dim,\n",
    "                    kernel_regularizer=l2(lmda),\n",
    "                    activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = build_logistic_model(input_dim, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 318 samples, validate on 30 samples\n",
      "Epoch 1/30\n",
      "318/318 [==============================] - 2s 6ms/step - loss: 1.5813 - acc: 0.2862 - val_loss: 1.2998 - val_acc: 0.5333\n",
      "Epoch 2/30\n",
      "318/318 [==============================] - 0s 245us/step - loss: 1.5182 - acc: 0.2862 - val_loss: 1.2464 - val_acc: 0.5333\n",
      "Epoch 3/30\n",
      "318/318 [==============================] - 0s 226us/step - loss: 1.4634 - acc: 0.2736 - val_loss: 1.2019 - val_acc: 0.5667\n",
      "Epoch 4/30\n",
      "318/318 [==============================] - 0s 215us/step - loss: 1.4185 - acc: 0.2830 - val_loss: 1.1648 - val_acc: 0.5333\n",
      "Epoch 5/30\n",
      "318/318 [==============================] - 0s 217us/step - loss: 1.3799 - acc: 0.2925 - val_loss: 1.1349 - val_acc: 0.5333\n",
      "Epoch 6/30\n",
      "318/318 [==============================] - 0s 217us/step - loss: 1.3470 - acc: 0.2830 - val_loss: 1.1106 - val_acc: 0.5333\n",
      "Epoch 7/30\n",
      "318/318 [==============================] - 0s 217us/step - loss: 1.3193 - acc: 0.2956 - val_loss: 1.0910 - val_acc: 0.5667\n",
      "Epoch 8/30\n",
      "318/318 [==============================] - 0s 233us/step - loss: 1.2953 - acc: 0.2956 - val_loss: 1.0750 - val_acc: 0.5667\n",
      "Epoch 9/30\n",
      "318/318 [==============================] - 0s 217us/step - loss: 1.2734 - acc: 0.2987 - val_loss: 1.0616 - val_acc: 0.5667\n",
      "Epoch 10/30\n",
      "318/318 [==============================] - 0s 227us/step - loss: 1.2550 - acc: 0.2956 - val_loss: 1.0502 - val_acc: 0.5667\n",
      "Epoch 11/30\n",
      "318/318 [==============================] - 0s 236us/step - loss: 1.2384 - acc: 0.3050 - val_loss: 1.0410 - val_acc: 0.6000\n",
      "Epoch 12/30\n",
      "318/318 [==============================] - 0s 211us/step - loss: 1.2232 - acc: 0.3082 - val_loss: 1.0339 - val_acc: 0.6333\n",
      "Epoch 13/30\n",
      "318/318 [==============================] - 0s 233us/step - loss: 1.2093 - acc: 0.3208 - val_loss: 1.0276 - val_acc: 0.6333\n",
      "Epoch 14/30\n",
      "318/318 [==============================] - 0s 217us/step - loss: 1.1970 - acc: 0.3176 - val_loss: 1.0224 - val_acc: 0.6333\n",
      "Epoch 15/30\n",
      "318/318 [==============================] - 0s 229us/step - loss: 1.1860 - acc: 0.3208 - val_loss: 1.0178 - val_acc: 0.6333\n",
      "Epoch 16/30\n",
      "318/318 [==============================] - 0s 245us/step - loss: 1.1757 - acc: 0.3239 - val_loss: 1.0148 - val_acc: 0.6000\n",
      "Epoch 17/30\n",
      "318/318 [==============================] - 0s 223us/step - loss: 1.1661 - acc: 0.3270 - val_loss: 1.0124 - val_acc: 0.6000\n",
      "Epoch 18/30\n",
      "318/318 [==============================] - 0s 248us/step - loss: 1.1579 - acc: 0.3302 - val_loss: 1.0100 - val_acc: 0.5333\n",
      "Epoch 19/30\n",
      "318/318 [==============================] - 0s 255us/step - loss: 1.1509 - acc: 0.3302 - val_loss: 1.0084 - val_acc: 0.5000\n",
      "Epoch 20/30\n",
      "318/318 [==============================] - 0s 226us/step - loss: 1.1432 - acc: 0.3365 - val_loss: 1.0072 - val_acc: 0.5000\n",
      "Epoch 21/30\n",
      "318/318 [==============================] - 0s 245us/step - loss: 1.1365 - acc: 0.3333 - val_loss: 1.0064 - val_acc: 0.5000\n",
      "Epoch 22/30\n",
      "318/318 [==============================] - 0s 245us/step - loss: 1.1309 - acc: 0.3365 - val_loss: 1.0057 - val_acc: 0.5000\n",
      "Epoch 23/30\n",
      "318/318 [==============================] - 0s 214us/step - loss: 1.1255 - acc: 0.3491 - val_loss: 1.0062 - val_acc: 0.5000\n",
      "Epoch 24/30\n",
      "318/318 [==============================] - 0s 226us/step - loss: 1.1208 - acc: 0.3522 - val_loss: 1.0067 - val_acc: 0.5000\n",
      "Epoch 25/30\n",
      "318/318 [==============================] - 0s 248us/step - loss: 1.1165 - acc: 0.3459 - val_loss: 1.0071 - val_acc: 0.4667\n",
      "Epoch 26/30\n",
      "318/318 [==============================] - 0s 226us/step - loss: 1.1123 - acc: 0.3396 - val_loss: 1.0077 - val_acc: 0.4667\n",
      "Epoch 27/30\n",
      "318/318 [==============================] - 0s 297us/step - loss: 1.1087 - acc: 0.3428 - val_loss: 1.0080 - val_acc: 0.4667\n",
      "Epoch 28/30\n",
      "318/318 [==============================] - 0s 305us/step - loss: 1.1047 - acc: 0.3491 - val_loss: 1.0089 - val_acc: 0.4333\n",
      "Epoch 29/30\n",
      "318/318 [==============================] - 0s 299us/step - loss: 1.1015 - acc: 0.3553 - val_loss: 1.0098 - val_acc: 0.4333\n",
      "Epoch 30/30\n",
      "318/318 [==============================] - 0s 308us/step - loss: 1.0987 - acc: 0.3522 - val_loss: 1.0104 - val_acc: 0.4333\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.0104328393936157\n",
      "Test accuracy: 0.4333333373069763\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test,axis = 1) \n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR With Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 3\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=2)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 10\n",
      "[[ 0 12]\n",
      " [ 1 12]\n",
      " [ 2 12]]\n",
      "Train on 312 samples, validate on 36 samples\n",
      "Epoch 1/20\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 1.4016 - acc: 0.3686 - val_loss: 1.3461 - val_acc: 0.3333\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.3527 - acc: 0.3590 - val_loss: 1.2973 - val_acc: 0.3333\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 0s 285us/step - loss: 1.3137 - acc: 0.3526 - val_loss: 1.2513 - val_acc: 0.3333\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 0s 266us/step - loss: 1.2797 - acc: 0.3526 - val_loss: 1.2185 - val_acc: 0.3333\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 0s 295us/step - loss: 1.2518 - acc: 0.3333 - val_loss: 1.1942 - val_acc: 0.3333\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 0s 301us/step - loss: 1.2294 - acc: 0.3397 - val_loss: 1.1750 - val_acc: 0.3333\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 0s 263us/step - loss: 1.2095 - acc: 0.3397 - val_loss: 1.1598 - val_acc: 0.2778\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 0s 275us/step - loss: 1.1943 - acc: 0.3429 - val_loss: 1.1472 - val_acc: 0.3056\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 0s 275us/step - loss: 1.1809 - acc: 0.3429 - val_loss: 1.1368 - val_acc: 0.2778\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.1684 - acc: 0.3429 - val_loss: 1.1277 - val_acc: 0.3056\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 0s 263us/step - loss: 1.1584 - acc: 0.3397 - val_loss: 1.1210 - val_acc: 0.3056\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 0s 256us/step - loss: 1.1505 - acc: 0.3622 - val_loss: 1.1164 - val_acc: 0.3056\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 0s 250us/step - loss: 1.1430 - acc: 0.3718 - val_loss: 1.1119 - val_acc: 0.3056\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 0s 259us/step - loss: 1.1361 - acc: 0.3814 - val_loss: 1.1080 - val_acc: 0.2778\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 0s 269us/step - loss: 1.1306 - acc: 0.3686 - val_loss: 1.1053 - val_acc: 0.2778\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.1253 - acc: 0.3654 - val_loss: 1.1040 - val_acc: 0.2778\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 0s 256us/step - loss: 1.1208 - acc: 0.3782 - val_loss: 1.1026 - val_acc: 0.3056\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 0s 259us/step - loss: 1.1163 - acc: 0.3878 - val_loss: 1.1012 - val_acc: 0.3333\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 0s 282us/step - loss: 1.1121 - acc: 0.3814 - val_loss: 1.1005 - val_acc: 0.3333\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 0s 279us/step - loss: 1.1088 - acc: 0.3878 - val_loss: 1.0996 - val_acc: 0.3611\n",
      "Running Fold 2 / 10\n",
      "[[ 0 12]\n",
      " [ 1 12]\n",
      " [ 2 12]]\n",
      "Train on 312 samples, validate on 36 samples\n",
      "Epoch 1/20\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 1.6407 - acc: 0.3109 - val_loss: 2.3523 - val_acc: 0.1944\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 0s 308us/step - loss: 1.5527 - acc: 0.3077 - val_loss: 2.1711 - val_acc: 0.1944\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 0s 253us/step - loss: 1.4811 - acc: 0.3045 - val_loss: 2.0146 - val_acc: 0.2222\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 0s 269us/step - loss: 1.4201 - acc: 0.3109 - val_loss: 1.8828 - val_acc: 0.2222\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 0s 275us/step - loss: 1.3711 - acc: 0.3077 - val_loss: 1.7620 - val_acc: 0.2222\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.3290 - acc: 0.3077 - val_loss: 1.6663 - val_acc: 0.2222\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 0s 263us/step - loss: 1.2960 - acc: 0.3109 - val_loss: 1.5837 - val_acc: 0.2222\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.2664 - acc: 0.3173 - val_loss: 1.5116 - val_acc: 0.2500\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 0s 275us/step - loss: 1.2411 - acc: 0.3333 - val_loss: 1.4499 - val_acc: 0.2500\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 0s 282us/step - loss: 1.2193 - acc: 0.3365 - val_loss: 1.3952 - val_acc: 0.2500\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 0s 295us/step - loss: 1.2009 - acc: 0.3429 - val_loss: 1.3480 - val_acc: 0.2500\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 0s 250us/step - loss: 1.1846 - acc: 0.3494 - val_loss: 1.2966 - val_acc: 0.2500\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 0s 282us/step - loss: 1.1683 - acc: 0.3462 - val_loss: 1.2623 - val_acc: 0.2500\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 0s 282us/step - loss: 1.1566 - acc: 0.3397 - val_loss: 1.2330 - val_acc: 0.2778\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 0s 285us/step - loss: 1.1465 - acc: 0.3365 - val_loss: 1.2088 - val_acc: 0.3056\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.1365 - acc: 0.3429 - val_loss: 1.1851 - val_acc: 0.3056\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.1282 - acc: 0.3462 - val_loss: 1.1657 - val_acc: 0.3056\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 0s 237us/step - loss: 1.1209 - acc: 0.3526 - val_loss: 1.1475 - val_acc: 0.3611\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 0s 266us/step - loss: 1.1141 - acc: 0.3494 - val_loss: 1.1314 - val_acc: 0.3333\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 0s 275us/step - loss: 1.1080 - acc: 0.3494 - val_loss: 1.1159 - val_acc: 0.3056\n",
      "Running Fold 3 / 10\n",
      "[[ 0 12]\n",
      " [ 1 12]\n",
      " [ 2 12]]\n",
      "Train on 312 samples, validate on 36 samples\n",
      "Epoch 1/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 1.3331 - acc: 0.3558 - val_loss: 1.2586 - val_acc: 0.2778\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 0s 333us/step - loss: 1.2675 - acc: 0.3654 - val_loss: 1.2224 - val_acc: 0.2778\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 0s 279us/step - loss: 1.2130 - acc: 0.3590 - val_loss: 1.1966 - val_acc: 0.3056\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 0s 243us/step - loss: 1.1737 - acc: 0.3686 - val_loss: 1.1779 - val_acc: 0.3333\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 0s 285us/step - loss: 1.1443 - acc: 0.3718 - val_loss: 1.1638 - val_acc: 0.3056\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 0s 263us/step - loss: 1.1213 - acc: 0.3654 - val_loss: 1.1529 - val_acc: 0.3333\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 0s 279us/step - loss: 1.1036 - acc: 0.3750 - val_loss: 1.1450 - val_acc: 0.3056\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 0s 295us/step - loss: 1.0904 - acc: 0.3846 - val_loss: 1.1390 - val_acc: 0.3056\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 0s 269us/step - loss: 1.0817 - acc: 0.4135 - val_loss: 1.1339 - val_acc: 0.3333\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 0s 250us/step - loss: 1.0734 - acc: 0.4103 - val_loss: 1.1299 - val_acc: 0.3333\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 0s 259us/step - loss: 1.0678 - acc: 0.4167 - val_loss: 1.1263 - val_acc: 0.3333\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 0s 266us/step - loss: 1.0625 - acc: 0.4263 - val_loss: 1.1234 - val_acc: 0.3333\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 0s 279us/step - loss: 1.0588 - acc: 0.4199 - val_loss: 1.1210 - val_acc: 0.3056\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 0s 269us/step - loss: 1.0556 - acc: 0.4135 - val_loss: 1.1188 - val_acc: 0.3333\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 0s 285us/step - loss: 1.0529 - acc: 0.4135 - val_loss: 1.1163 - val_acc: 0.3333\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.0506 - acc: 0.4167 - val_loss: 1.1141 - val_acc: 0.3333\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 0s 275us/step - loss: 1.0481 - acc: 0.4103 - val_loss: 1.1129 - val_acc: 0.3333\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 0s 263us/step - loss: 1.0464 - acc: 0.4167 - val_loss: 1.1118 - val_acc: 0.3611\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.0450 - acc: 0.4167 - val_loss: 1.1113 - val_acc: 0.3611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "312/312 [==============================] - 0s 259us/step - loss: 1.0435 - acc: 0.4135 - val_loss: 1.1102 - val_acc: 0.3611\n",
      "Running Fold 4 / 10\n",
      "[[ 0 12]\n",
      " [ 1 12]\n",
      " [ 2 12]]\n",
      "Train on 312 samples, validate on 36 samples\n",
      "Epoch 1/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 1.4286 - acc: 0.3237 - val_loss: 1.2332 - val_acc: 0.4167\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.3571 - acc: 0.3269 - val_loss: 1.1875 - val_acc: 0.4167\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 0s 275us/step - loss: 1.2982 - acc: 0.3365 - val_loss: 1.1534 - val_acc: 0.4167\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 0s 259us/step - loss: 1.2546 - acc: 0.3301 - val_loss: 1.1276 - val_acc: 0.4167\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.2200 - acc: 0.3365 - val_loss: 1.1081 - val_acc: 0.4167\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 0s 284us/step - loss: 1.1919 - acc: 0.3269 - val_loss: 1.0937 - val_acc: 0.4444\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 0s 279us/step - loss: 1.1695 - acc: 0.3333 - val_loss: 1.0824 - val_acc: 0.4444\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.1521 - acc: 0.3365 - val_loss: 1.0737 - val_acc: 0.4444\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 0s 282us/step - loss: 1.1388 - acc: 0.3365 - val_loss: 1.0656 - val_acc: 0.4444\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 0s 250us/step - loss: 1.1271 - acc: 0.3397 - val_loss: 1.0601 - val_acc: 0.4722\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.1179 - acc: 0.3333 - val_loss: 1.0541 - val_acc: 0.4722\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 0s 253us/step - loss: 1.1103 - acc: 0.3462 - val_loss: 1.0490 - val_acc: 0.4444\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 0s 311us/step - loss: 1.1034 - acc: 0.3558 - val_loss: 1.0444 - val_acc: 0.4444\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.0977 - acc: 0.3462 - val_loss: 1.0397 - val_acc: 0.4167\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 0s 247us/step - loss: 1.0924 - acc: 0.3494 - val_loss: 1.0372 - val_acc: 0.4167\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 0s 231us/step - loss: 1.0881 - acc: 0.3558 - val_loss: 1.0352 - val_acc: 0.3889\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 0s 266us/step - loss: 1.0846 - acc: 0.3494 - val_loss: 1.0327 - val_acc: 0.3889\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 0s 282us/step - loss: 1.0809 - acc: 0.3558 - val_loss: 1.0298 - val_acc: 0.3889\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 0s 259us/step - loss: 1.0781 - acc: 0.3622 - val_loss: 1.0269 - val_acc: 0.3889\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 0s 263us/step - loss: 1.0753 - acc: 0.3718 - val_loss: 1.0256 - val_acc: 0.3889\n",
      "Running Fold 5 / 10\n",
      "[[ 0 12]\n",
      " [ 1 12]\n",
      " [ 2 12]]\n",
      "Train on 312 samples, validate on 36 samples\n",
      "Epoch 1/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 1.4149 - acc: 0.3141 - val_loss: 1.2966 - val_acc: 0.3056\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 0s 269us/step - loss: 1.3843 - acc: 0.3333 - val_loss: 1.2740 - val_acc: 0.3056\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 0s 266us/step - loss: 1.3559 - acc: 0.3365 - val_loss: 1.2550 - val_acc: 0.3611\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 0s 279us/step - loss: 1.3305 - acc: 0.3333 - val_loss: 1.2368 - val_acc: 0.3611\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 0s 269us/step - loss: 1.3067 - acc: 0.3494 - val_loss: 1.2210 - val_acc: 0.3611\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 0s 263us/step - loss: 1.2866 - acc: 0.3526 - val_loss: 1.2065 - val_acc: 0.3611\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 0s 259us/step - loss: 1.2679 - acc: 0.3462 - val_loss: 1.1929 - val_acc: 0.3611\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 0s 269us/step - loss: 1.2509 - acc: 0.3526 - val_loss: 1.1811 - val_acc: 0.4167\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 0s 279us/step - loss: 1.2349 - acc: 0.3590 - val_loss: 1.1693 - val_acc: 0.4167\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 0s 250us/step - loss: 1.2196 - acc: 0.3590 - val_loss: 1.1599 - val_acc: 0.4167\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 0s 266us/step - loss: 1.2071 - acc: 0.3462 - val_loss: 1.1514 - val_acc: 0.4167\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 0s 266us/step - loss: 1.1955 - acc: 0.3494 - val_loss: 1.1429 - val_acc: 0.4444\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 0s 269us/step - loss: 1.1844 - acc: 0.3494 - val_loss: 1.1351 - val_acc: 0.4722\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 0s 269us/step - loss: 1.1750 - acc: 0.3590 - val_loss: 1.1282 - val_acc: 0.4722\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 0s 279us/step - loss: 1.1653 - acc: 0.3654 - val_loss: 1.1219 - val_acc: 0.4722\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 0s 311us/step - loss: 1.1570 - acc: 0.3654 - val_loss: 1.1161 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 0s 295us/step - loss: 1.1500 - acc: 0.3782 - val_loss: 1.1110 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 0s 256us/step - loss: 1.1429 - acc: 0.3686 - val_loss: 1.1065 - val_acc: 0.4722\n",
      "Epoch 19/20\n",
      "312/312 [==============================] - 0s 243us/step - loss: 1.1360 - acc: 0.3654 - val_loss: 1.1021 - val_acc: 0.4722\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 0s 288us/step - loss: 1.1302 - acc: 0.3654 - val_loss: 1.0976 - val_acc: 0.4167\n",
      "Running Fold 6 / 10\n",
      "[[ 0 12]\n",
      " [ 1 12]\n",
      " [ 2 12]]\n",
      "Train on 312 samples, validate on 36 samples\n",
      "Epoch 1/20\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 1.5150 - acc: 0.3173 - val_loss: 1.5471 - val_acc: 0.2778\n",
      "Epoch 2/20\n",
      "312/312 [==============================] - 0s 292us/step - loss: 1.4530 - acc: 0.3333 - val_loss: 1.4895 - val_acc: 0.2778\n",
      "Epoch 3/20\n",
      "312/312 [==============================] - 0s 293us/step - loss: 1.3967 - acc: 0.3429 - val_loss: 1.4446 - val_acc: 0.3056\n",
      "Epoch 4/20\n",
      "312/312 [==============================] - 0s 256us/step - loss: 1.3506 - acc: 0.3429 - val_loss: 1.4074 - val_acc: 0.2778\n",
      "Epoch 5/20\n",
      "312/312 [==============================] - 0s 275us/step - loss: 1.3154 - acc: 0.3622 - val_loss: 1.3763 - val_acc: 0.2500\n",
      "Epoch 6/20\n",
      "312/312 [==============================] - 0s 272us/step - loss: 1.2851 - acc: 0.3526 - val_loss: 1.3482 - val_acc: 0.2500\n",
      "Epoch 7/20\n",
      "312/312 [==============================] - 0s 285us/step - loss: 1.2584 - acc: 0.3590 - val_loss: 1.3248 - val_acc: 0.2778\n",
      "Epoch 8/20\n",
      "312/312 [==============================] - 0s 282us/step - loss: 1.2344 - acc: 0.3654 - val_loss: 1.3025 - val_acc: 0.3056\n",
      "Epoch 9/20\n",
      "312/312 [==============================] - 0s 301us/step - loss: 1.2128 - acc: 0.3686 - val_loss: 1.2843 - val_acc: 0.3056\n",
      "Epoch 10/20\n",
      "312/312 [==============================] - 0s 266us/step - loss: 1.1934 - acc: 0.3686 - val_loss: 1.2650 - val_acc: 0.3056\n",
      "Epoch 11/20\n",
      "312/312 [==============================] - 0s 285us/step - loss: 1.1762 - acc: 0.3878 - val_loss: 1.2508 - val_acc: 0.3056\n",
      "Epoch 12/20\n",
      "312/312 [==============================] - 0s 266us/step - loss: 1.1602 - acc: 0.4071 - val_loss: 1.2370 - val_acc: 0.3056\n",
      "Epoch 13/20\n",
      "312/312 [==============================] - 0s 282us/step - loss: 1.1466 - acc: 0.4135 - val_loss: 1.2250 - val_acc: 0.3333\n",
      "Epoch 14/20\n",
      "312/312 [==============================] - 0s 259us/step - loss: 1.1341 - acc: 0.4103 - val_loss: 1.2143 - val_acc: 0.3333\n",
      "Epoch 15/20\n",
      "312/312 [==============================] - 0s 271us/step - loss: 1.1235 - acc: 0.4167 - val_loss: 1.2044 - val_acc: 0.3333\n",
      "Epoch 16/20\n",
      "312/312 [==============================] - 0s 250us/step - loss: 1.1130 - acc: 0.3910 - val_loss: 1.1960 - val_acc: 0.3333\n",
      "Epoch 17/20\n",
      "312/312 [==============================] - 0s 271us/step - loss: 1.1042 - acc: 0.3910 - val_loss: 1.1897 - val_acc: 0.3611\n",
      "Epoch 18/20\n",
      "312/312 [==============================] - 0s 304us/step - loss: 1.0954 - acc: 0.3910 - val_loss: 1.1830 - val_acc: 0.3889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "312/312 [==============================] - 0s 295us/step - loss: 1.0888 - acc: 0.3974 - val_loss: 1.1787 - val_acc: 0.3889\n",
      "Epoch 20/20\n",
      "312/312 [==============================] - 0s 253us/step - loss: 1.0820 - acc: 0.3974 - val_loss: 1.1733 - val_acc: 0.3889\n",
      "Running Fold 7 / 10\n",
      "[[ 0 11]\n",
      " [ 1 11]\n",
      " [ 2 11]]\n",
      "Train on 315 samples, validate on 33 samples\n",
      "Epoch 1/20\n",
      "315/315 [==============================] - 2s 5ms/step - loss: 1.5292 - acc: 0.3429 - val_loss: 1.4301 - val_acc: 0.3636\n",
      "Epoch 2/20\n",
      "315/315 [==============================] - 0s 260us/step - loss: 1.4611 - acc: 0.3238 - val_loss: 1.3733 - val_acc: 0.3636\n",
      "Epoch 3/20\n",
      "315/315 [==============================] - 0s 276us/step - loss: 1.4035 - acc: 0.3302 - val_loss: 1.3254 - val_acc: 0.3636\n",
      "Epoch 4/20\n",
      "315/315 [==============================] - 0s 244us/step - loss: 1.3559 - acc: 0.3333 - val_loss: 1.2848 - val_acc: 0.3636\n",
      "Epoch 5/20\n",
      "315/315 [==============================] - 0s 251us/step - loss: 1.3154 - acc: 0.3333 - val_loss: 1.2510 - val_acc: 0.3636\n",
      "Epoch 6/20\n",
      "315/315 [==============================] - 0s 254us/step - loss: 1.2819 - acc: 0.3460 - val_loss: 1.2225 - val_acc: 0.3939\n",
      "Epoch 7/20\n",
      "315/315 [==============================] - 0s 232us/step - loss: 1.2534 - acc: 0.3587 - val_loss: 1.1989 - val_acc: 0.3939\n",
      "Epoch 8/20\n",
      "315/315 [==============================] - 0s 257us/step - loss: 1.2285 - acc: 0.3587 - val_loss: 1.1783 - val_acc: 0.3939\n",
      "Epoch 9/20\n",
      "315/315 [==============================] - 0s 260us/step - loss: 1.2073 - acc: 0.3683 - val_loss: 1.1614 - val_acc: 0.3636\n",
      "Epoch 10/20\n",
      "315/315 [==============================] - 0s 254us/step - loss: 1.1892 - acc: 0.3683 - val_loss: 1.1461 - val_acc: 0.3939\n",
      "Epoch 11/20\n",
      "315/315 [==============================] - 0s 270us/step - loss: 1.1729 - acc: 0.3778 - val_loss: 1.1339 - val_acc: 0.3939\n",
      "Epoch 12/20\n",
      "315/315 [==============================] - 0s 273us/step - loss: 1.1588 - acc: 0.3683 - val_loss: 1.1236 - val_acc: 0.4242\n",
      "Epoch 13/20\n",
      "315/315 [==============================] - 0s 251us/step - loss: 1.1464 - acc: 0.3746 - val_loss: 1.1149 - val_acc: 0.4242\n",
      "Epoch 14/20\n",
      "315/315 [==============================] - 0s 263us/step - loss: 1.1355 - acc: 0.3841 - val_loss: 1.1072 - val_acc: 0.4848\n",
      "Epoch 15/20\n",
      "315/315 [==============================] - 0s 251us/step - loss: 1.1255 - acc: 0.3810 - val_loss: 1.1002 - val_acc: 0.4848\n",
      "Epoch 16/20\n",
      "315/315 [==============================] - 0s 251us/step - loss: 1.1162 - acc: 0.3905 - val_loss: 1.0948 - val_acc: 0.4848\n",
      "Epoch 17/20\n",
      "315/315 [==============================] - 0s 260us/step - loss: 1.1088 - acc: 0.3905 - val_loss: 1.0896 - val_acc: 0.4545\n",
      "Epoch 18/20\n",
      "315/315 [==============================] - 0s 241us/step - loss: 1.1020 - acc: 0.3905 - val_loss: 1.0859 - val_acc: 0.4242\n",
      "Epoch 19/20\n",
      "315/315 [==============================] - 0s 241us/step - loss: 1.0958 - acc: 0.3810 - val_loss: 1.0823 - val_acc: 0.4242\n",
      "Epoch 20/20\n",
      "315/315 [==============================] - 0s 254us/step - loss: 1.0899 - acc: 0.3905 - val_loss: 1.0796 - val_acc: 0.4242\n",
      "Running Fold 8 / 10\n",
      "[[ 0 11]\n",
      " [ 1 11]\n",
      " [ 2 11]]\n",
      "Train on 315 samples, validate on 33 samples\n",
      "Epoch 1/20\n",
      "315/315 [==============================] - 2s 5ms/step - loss: 1.2890 - acc: 0.3587 - val_loss: 1.4717 - val_acc: 0.4242\n",
      "Epoch 2/20\n",
      "315/315 [==============================] - 0s 368us/step - loss: 1.2692 - acc: 0.3619 - val_loss: 1.4420 - val_acc: 0.4242\n",
      "Epoch 3/20\n",
      "315/315 [==============================] - 0s 289us/step - loss: 1.2515 - acc: 0.3524 - val_loss: 1.4150 - val_acc: 0.4242\n",
      "Epoch 4/20\n",
      "315/315 [==============================] - 0s 270us/step - loss: 1.2352 - acc: 0.3619 - val_loss: 1.3913 - val_acc: 0.4545\n",
      "Epoch 5/20\n",
      "315/315 [==============================] - 0s 346us/step - loss: 1.2204 - acc: 0.3587 - val_loss: 1.3693 - val_acc: 0.4545\n",
      "Epoch 6/20\n",
      "315/315 [==============================] - 0s 549us/step - loss: 1.2071 - acc: 0.3746 - val_loss: 1.3500 - val_acc: 0.4545\n",
      "Epoch 7/20\n",
      "315/315 [==============================] - 0s 362us/step - loss: 1.1948 - acc: 0.3683 - val_loss: 1.3323 - val_acc: 0.4545\n",
      "Epoch 8/20\n",
      "315/315 [==============================] - 0s 298us/step - loss: 1.1846 - acc: 0.3651 - val_loss: 1.3151 - val_acc: 0.4545\n",
      "Epoch 9/20\n",
      "315/315 [==============================] - 0s 333us/step - loss: 1.1738 - acc: 0.3683 - val_loss: 1.2996 - val_acc: 0.4545\n",
      "Epoch 10/20\n",
      "315/315 [==============================] - 0s 412us/step - loss: 1.1648 - acc: 0.3714 - val_loss: 1.2830 - val_acc: 0.4545\n",
      "Epoch 11/20\n",
      "315/315 [==============================] - 0s 374us/step - loss: 1.1560 - acc: 0.3651 - val_loss: 1.2705 - val_acc: 0.4545\n",
      "Epoch 12/20\n",
      "315/315 [==============================] - 0s 352us/step - loss: 1.1482 - acc: 0.3683 - val_loss: 1.2591 - val_acc: 0.4545\n",
      "Epoch 13/20\n",
      "315/315 [==============================] - 0s 463us/step - loss: 1.1408 - acc: 0.3651 - val_loss: 1.2499 - val_acc: 0.4242\n",
      "Epoch 14/20\n",
      "315/315 [==============================] - 0s 435us/step - loss: 1.1347 - acc: 0.3587 - val_loss: 1.2402 - val_acc: 0.4242\n",
      "Epoch 15/20\n",
      "315/315 [==============================] - 0s 558us/step - loss: 1.1281 - acc: 0.3524 - val_loss: 1.2311 - val_acc: 0.4242\n",
      "Epoch 16/20\n",
      "315/315 [==============================] - 0s 460us/step - loss: 1.1219 - acc: 0.3524 - val_loss: 1.2220 - val_acc: 0.4242\n",
      "Epoch 17/20\n",
      "315/315 [==============================] - 0s 416us/step - loss: 1.1166 - acc: 0.3619 - val_loss: 1.2142 - val_acc: 0.3939\n",
      "Epoch 18/20\n",
      "315/315 [==============================] - 0s 416us/step - loss: 1.1120 - acc: 0.3746 - val_loss: 1.2068 - val_acc: 0.3939\n",
      "Epoch 19/20\n",
      "315/315 [==============================] - 0s 441us/step - loss: 1.1066 - acc: 0.3619 - val_loss: 1.2005 - val_acc: 0.3939\n",
      "Epoch 20/20\n",
      "315/315 [==============================] - 0s 524us/step - loss: 1.1028 - acc: 0.3746 - val_loss: 1.1944 - val_acc: 0.3636\n",
      "Running Fold 9 / 10\n",
      "[[ 0 11]\n",
      " [ 1 11]\n",
      " [ 2 11]]\n",
      "Train on 315 samples, validate on 33 samples\n",
      "Epoch 1/20\n",
      "315/315 [==============================] - 2s 6ms/step - loss: 1.4617 - acc: 0.3905 - val_loss: 1.5577 - val_acc: 0.3333\n",
      "Epoch 2/20\n",
      "315/315 [==============================] - 0s 289us/step - loss: 1.3804 - acc: 0.3905 - val_loss: 1.4502 - val_acc: 0.3030\n",
      "Epoch 3/20\n",
      "315/315 [==============================] - 0s 305us/step - loss: 1.3141 - acc: 0.3841 - val_loss: 1.3632 - val_acc: 0.3030\n",
      "Epoch 4/20\n",
      "315/315 [==============================] - 0s 365us/step - loss: 1.2610 - acc: 0.3968 - val_loss: 1.2916 - val_acc: 0.3333\n",
      "Epoch 5/20\n",
      "315/315 [==============================] - 0s 352us/step - loss: 1.2182 - acc: 0.4159 - val_loss: 1.2384 - val_acc: 0.3333\n",
      "Epoch 6/20\n",
      "315/315 [==============================] - 0s 428us/step - loss: 1.1863 - acc: 0.4222 - val_loss: 1.1981 - val_acc: 0.3636\n",
      "Epoch 7/20\n",
      "315/315 [==============================] - 0s 428us/step - loss: 1.1624 - acc: 0.4349 - val_loss: 1.1673 - val_acc: 0.4242\n",
      "Epoch 8/20\n",
      "315/315 [==============================] - 0s 400us/step - loss: 1.1428 - acc: 0.4413 - val_loss: 1.1452 - val_acc: 0.4242\n",
      "Epoch 9/20\n",
      "315/315 [==============================] - 0s 368us/step - loss: 1.1281 - acc: 0.4317 - val_loss: 1.1287 - val_acc: 0.3939\n",
      "Epoch 10/20\n",
      "315/315 [==============================] - 0s 346us/step - loss: 1.1165 - acc: 0.4286 - val_loss: 1.1162 - val_acc: 0.3939\n",
      "Epoch 11/20\n",
      "315/315 [==============================] - 0s 324us/step - loss: 1.1073 - acc: 0.4286 - val_loss: 1.1059 - val_acc: 0.4242\n",
      "Epoch 12/20\n",
      "315/315 [==============================] - 0s 330us/step - loss: 1.0994 - acc: 0.4254 - val_loss: 1.0981 - val_acc: 0.4242\n",
      "Epoch 13/20\n",
      "315/315 [==============================] - 0s 349us/step - loss: 1.0933 - acc: 0.4317 - val_loss: 1.0920 - val_acc: 0.4242\n",
      "Epoch 14/20\n",
      "315/315 [==============================] - 0s 368us/step - loss: 1.0881 - acc: 0.4349 - val_loss: 1.0874 - val_acc: 0.4242\n",
      "Epoch 15/20\n",
      "315/315 [==============================] - 0s 374us/step - loss: 1.0836 - acc: 0.4413 - val_loss: 1.0830 - val_acc: 0.4242\n",
      "Epoch 16/20\n",
      "315/315 [==============================] - 0s 362us/step - loss: 1.0798 - acc: 0.4381 - val_loss: 1.0796 - val_acc: 0.4242\n",
      "Epoch 17/20\n",
      "315/315 [==============================] - 0s 400us/step - loss: 1.0769 - acc: 0.4286 - val_loss: 1.0764 - val_acc: 0.4242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "315/315 [==============================] - 0s 455us/step - loss: 1.0740 - acc: 0.4349 - val_loss: 1.0737 - val_acc: 0.4242\n",
      "Epoch 19/20\n",
      "315/315 [==============================] - 0s 447us/step - loss: 1.0718 - acc: 0.4349 - val_loss: 1.0718 - val_acc: 0.4242\n",
      "Epoch 20/20\n",
      "315/315 [==============================] - 0s 476us/step - loss: 1.0694 - acc: 0.4349 - val_loss: 1.0692 - val_acc: 0.3939\n",
      "Running Fold 10 / 10\n",
      "[[ 0 11]\n",
      " [ 1 11]\n",
      " [ 2 11]]\n",
      "Train on 315 samples, validate on 33 samples\n",
      "Epoch 1/20\n",
      "315/315 [==============================] - 2s 7ms/step - loss: 1.6900 - acc: 0.3079 - val_loss: 1.4531 - val_acc: 0.3030\n",
      "Epoch 2/20\n",
      "315/315 [==============================] - 0s 320us/step - loss: 1.5861 - acc: 0.3143 - val_loss: 1.3956 - val_acc: 0.3030\n",
      "Epoch 3/20\n",
      "315/315 [==============================] - 0s 298us/step - loss: 1.5007 - acc: 0.3048 - val_loss: 1.3479 - val_acc: 0.3030\n",
      "Epoch 4/20\n",
      "315/315 [==============================] - 0s 336us/step - loss: 1.4285 - acc: 0.3111 - val_loss: 1.3087 - val_acc: 0.3030\n",
      "Epoch 5/20\n",
      "315/315 [==============================] - 0s 333us/step - loss: 1.3669 - acc: 0.3143 - val_loss: 1.2768 - val_acc: 0.2424\n",
      "Epoch 6/20\n",
      "315/315 [==============================] - 0s 374us/step - loss: 1.3149 - acc: 0.3206 - val_loss: 1.2503 - val_acc: 0.2424\n",
      "Epoch 7/20\n",
      "315/315 [==============================] - 0s 308us/step - loss: 1.2714 - acc: 0.3238 - val_loss: 1.2277 - val_acc: 0.2727\n",
      "Epoch 8/20\n",
      "315/315 [==============================] - 0s 292us/step - loss: 1.2355 - acc: 0.3397 - val_loss: 1.2093 - val_acc: 0.3030\n",
      "Epoch 9/20\n",
      "315/315 [==============================] - 0s 320us/step - loss: 1.2051 - acc: 0.3492 - val_loss: 1.1943 - val_acc: 0.2727\n",
      "Epoch 10/20\n",
      "315/315 [==============================] - 0s 311us/step - loss: 1.1799 - acc: 0.3651 - val_loss: 1.1807 - val_acc: 0.2727\n",
      "Epoch 11/20\n",
      "315/315 [==============================] - ETA: 0s - loss: 1.1716 - acc: 0.369 - 0s 317us/step - loss: 1.1575 - acc: 0.3683 - val_loss: 1.1714 - val_acc: 0.3030\n",
      "Epoch 12/20\n",
      "315/315 [==============================] - 0s 311us/step - loss: 1.1404 - acc: 0.3810 - val_loss: 1.1637 - val_acc: 0.3636\n",
      "Epoch 13/20\n",
      "315/315 [==============================] - 0s 305us/step - loss: 1.1255 - acc: 0.3810 - val_loss: 1.1568 - val_acc: 0.3636\n",
      "Epoch 14/20\n",
      "315/315 [==============================] - 0s 295us/step - loss: 1.1138 - acc: 0.3873 - val_loss: 1.1515 - val_acc: 0.3636\n",
      "Epoch 15/20\n",
      "315/315 [==============================] - 0s 295us/step - loss: 1.1040 - acc: 0.3841 - val_loss: 1.1478 - val_acc: 0.3333\n",
      "Epoch 16/20\n",
      "315/315 [==============================] - 0s 308us/step - loss: 1.0958 - acc: 0.3841 - val_loss: 1.1454 - val_acc: 0.3636\n",
      "Epoch 17/20\n",
      "315/315 [==============================] - 0s 317us/step - loss: 1.0893 - acc: 0.3968 - val_loss: 1.1442 - val_acc: 0.3939\n",
      "Epoch 18/20\n",
      "315/315 [==============================] - 0s 295us/step - loss: 1.0829 - acc: 0.4000 - val_loss: 1.1434 - val_acc: 0.3636\n",
      "Epoch 19/20\n",
      "315/315 [==============================] - 0s 320us/step - loss: 1.0777 - acc: 0.3905 - val_loss: 1.1431 - val_acc: 0.3636\n",
      "Epoch 20/20\n",
      "315/315 [==============================] - 0s 298us/step - loss: 1.0737 - acc: 0.3968 - val_loss: 1.1430 - val_acc: 0.3636\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "\n",
    "labels = df['flow_rate'].values\n",
    "data = x\n",
    "\n",
    "labels[labels == 1800] = 0\n",
    "labels[labels == 3600] = 1\n",
    "labels[labels == 7200] = 2\n",
    "\n",
    "one_hot = np_utils.to_categorical(labels, nb_classes) \n",
    "\n",
    "skf = StratifiedKFold(df['flow_rate'].values, n_folds=n_folds, shuffle=True)\n",
    "avg_acc = 0\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i, (train, test) in enumerate(skf):\n",
    "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    model = None # Clearing the NN.\n",
    "    model = build_logistic_model(input_dim, nb_classes)\n",
    "    \n",
    "    std = np.std(data[train],0)\n",
    "    mean = np.mean(data[train],0)\n",
    "    \n",
    "    x_train = (data[train]-mean)/std\n",
    "    x_test = (data[test] - mean)/std        \n",
    "    \n",
    "    avg_acc += train_and_evaluate_model(model, x_train, one_hot[train], x_test, one_hot[test])\n",
    "    \n",
    "    # Predict the values from the validation dataset\n",
    "    Y_pred = model.predict(x_test)\n",
    "    # Convert predictions classes to one hot vectors \n",
    "    Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "    # Convert validation observations to one hot vectors\n",
    "    Y_true = np.argmax(one_hot[test],axis = 1) \n",
    "    \n",
    "    y_true.extend(Y_true)\n",
    "    y_pred.extend(Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy:  0.3767676767676768\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Accuracy: \", avg_acc/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(np.array(y_true), np.array(y_pred)) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(3)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
