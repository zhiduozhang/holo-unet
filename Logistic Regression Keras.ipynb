{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment\n",
    "# experiment = Experiment(api_key=\"xktj4EX0zB8YcQ3BEaFwOQYpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duo\\Anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\train\\\\\"\n",
    "train_csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\train\\\\ids.csv\"\n",
    "test_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\test\\\\\"\n",
    "test_csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\test\\\\ids.csv\"\n",
    "\n",
    "dest_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\\"\n",
    "\n",
    "csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\ids.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv,index_col=0).sample(frac=1)\n",
    "\n",
    "df['log_volume'] = df['volume'].apply(np.log)\n",
    "\n",
    "x = df.drop(columns=['name','date','flow_rate','source','moments','inertia_tensor'])\n",
    "x = standardize = preprocessing.scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>flow_rate</th>\n",
       "      <th>source</th>\n",
       "      <th>peak_val</th>\n",
       "      <th>area</th>\n",
       "      <th>volume</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>euler_number</th>\n",
       "      <th>extent</th>\n",
       "      <th>mean_intensity</th>\n",
       "      <th>moments</th>\n",
       "      <th>orientation</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>inertia_tensor</th>\n",
       "      <th>cluster</th>\n",
       "      <th>num_peaks</th>\n",
       "      <th>log_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>2017.11.23</td>\n",
       "      <td>1800</td>\n",
       "      <td>63.190 s.tifheightmap.mat</td>\n",
       "      <td>9.263165</td>\n",
       "      <td>7400</td>\n",
       "      <td>25290.418483</td>\n",
       "      <td>0.964196</td>\n",
       "      <td>0</td>\n",
       "      <td>0.252870</td>\n",
       "      <td>3.417162</td>\n",
       "      <td>[[7.40100000e+03 1.12974800e+06 2.06903164e+08...</td>\n",
       "      <td>-1.311872</td>\n",
       "      <td>796.139177</td>\n",
       "      <td>[[  650.68892314 -1140.5592428 ]\\r\\n [-1140.55...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10.138181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>193_flipped</td>\n",
       "      <td>2017.11.23</td>\n",
       "      <td>7200</td>\n",
       "      <td>17.00 s.tifheightmap.mat</td>\n",
       "      <td>22.020838</td>\n",
       "      <td>8174</td>\n",
       "      <td>90861.108863</td>\n",
       "      <td>0.866445</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612744</td>\n",
       "      <td>11.115868</td>\n",
       "      <td>[[8.17400000e+03 5.57136000e+05 4.89365720e+07...</td>\n",
       "      <td>-1.238136</td>\n",
       "      <td>482.315801</td>\n",
       "      <td>[[ 480.1139295  -337.80767374]\\r\\n [-337.80767...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.417087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>58_flipped</td>\n",
       "      <td>2017.11.17</td>\n",
       "      <td>7200</td>\n",
       "      <td>21.65 s.tifheightmap.mat</td>\n",
       "      <td>6.398700</td>\n",
       "      <td>2113</td>\n",
       "      <td>8579.705339</td>\n",
       "      <td>0.926920</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772006</td>\n",
       "      <td>4.009208</td>\n",
       "      <td>[[2.14000000e+03 8.31620000e+04 4.24636000e+06...</td>\n",
       "      <td>1.538944</td>\n",
       "      <td>206.568542</td>\n",
       "      <td>[[ 67.23740305  12.97797057]\\r\\n [ 12.97797057...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.057155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>2017.11.17</td>\n",
       "      <td>7200</td>\n",
       "      <td>3.70 s.tifheightmap.mat</td>\n",
       "      <td>6.696278</td>\n",
       "      <td>6441</td>\n",
       "      <td>24631.191797</td>\n",
       "      <td>0.976499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692134</td>\n",
       "      <td>3.824125</td>\n",
       "      <td>[[6.44100000e+03 6.26642000e+05 7.64434660e+07...</td>\n",
       "      <td>-1.531355</td>\n",
       "      <td>447.663997</td>\n",
       "      <td>[[ 115.35188709  -90.41671324]\\r\\n [ -90.41671...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.111769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>132_flipped</td>\n",
       "      <td>2017.11.23</td>\n",
       "      <td>1800</td>\n",
       "      <td>26.20 s.tifheightmap.mat</td>\n",
       "      <td>9.358412</td>\n",
       "      <td>5355</td>\n",
       "      <td>24621.497101</td>\n",
       "      <td>0.668227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>4.597852</td>\n",
       "      <td>[[5.35500000e+03 2.30840000e+05 1.30236900e+07...</td>\n",
       "      <td>-1.151411</td>\n",
       "      <td>335.622366</td>\n",
       "      <td>[[ 388.86804988 -102.91215484]\\r\\n [-102.91215...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.111375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name        date  flow_rate                     source   peak_val  \\\n",
       "146          146  2017.11.23       1800  63.190 s.tifheightmap.mat   9.263165   \n",
       "306  193_flipped  2017.11.23       7200   17.00 s.tifheightmap.mat  22.020838   \n",
       "356   58_flipped  2017.11.17       7200   21.65 s.tifheightmap.mat   6.398700   \n",
       "70            70  2017.11.17       7200    3.70 s.tifheightmap.mat   6.696278   \n",
       "239  132_flipped  2017.11.23       1800   26.20 s.tifheightmap.mat   9.358412   \n",
       "\n",
       "     area        volume  eccentricity  euler_number    extent  mean_intensity  \\\n",
       "146  7400  25290.418483      0.964196             0  0.252870        3.417162   \n",
       "306  8174  90861.108863      0.866445             0  0.612744       11.115868   \n",
       "356  2113   8579.705339      0.926920             1  0.772006        4.009208   \n",
       "70   6441  24631.191797      0.976499             1  0.692134        3.824125   \n",
       "239  5355  24621.497101      0.668227             0  0.767742        4.597852   \n",
       "\n",
       "                                               moments  orientation  \\\n",
       "146  [[7.40100000e+03 1.12974800e+06 2.06903164e+08...    -1.311872   \n",
       "306  [[8.17400000e+03 5.57136000e+05 4.89365720e+07...    -1.238136   \n",
       "356  [[2.14000000e+03 8.31620000e+04 4.24636000e+06...     1.538944   \n",
       "70   [[6.44100000e+03 6.26642000e+05 7.64434660e+07...    -1.531355   \n",
       "239  [[5.35500000e+03 2.30840000e+05 1.30236900e+07...    -1.151411   \n",
       "\n",
       "      perimeter                                     inertia_tensor  cluster  \\\n",
       "146  796.139177  [[  650.68892314 -1140.5592428 ]\\r\\n [-1140.55...        2   \n",
       "306  482.315801  [[ 480.1139295  -337.80767374]\\r\\n [-337.80767...        0   \n",
       "356  206.568542  [[ 67.23740305  12.97797057]\\r\\n [ 12.97797057...        2   \n",
       "70   447.663997  [[ 115.35188709  -90.41671324]\\r\\n [ -90.41671...        2   \n",
       "239  335.622366  [[ 388.86804988 -102.91215484]\\r\\n [-102.91215...        0   \n",
       "\n",
       "     num_peaks  log_volume  \n",
       "146          2   10.138181  \n",
       "306          1   11.417087  \n",
       "356          1    9.057155  \n",
       "70           1   10.111769  \n",
       "239          1   10.111375  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(df.shape[0]/10)\n",
    "\n",
    "x_test = np.array(x[:test_size])\n",
    "y_test = df['flow_rate'][:test_size].values\n",
    "\n",
    "x_train = np.array(x[test_size:])\n",
    "y_train = df['flow_rate'][test_size:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0 ...   0   0 103]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ...,  0,  0, 13], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.bincount(y_train))\n",
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 3\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 1800] = 0\n",
    "y_train[y_train == 3600] = 1\n",
    "y_train[y_train == 7200] = 2\n",
    "\n",
    "y_test[y_test == 1800] = 0\n",
    "y_test[y_test == 3600] = 1\n",
    "y_test[y_test == 7200] = 2\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes) \n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmda = 0.01\n",
    "\n",
    "def build_logistic_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim, input_dim=input_dim,\n",
    "                    kernel_regularizer=l2(lmda),\n",
    "                    activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = build_logistic_model(input_dim, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 362 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "362/362 [==============================] - 0s 784us/step - loss: 1.7984 - acc: 0.3094 - val_loss: 1.6247 - val_acc: 0.3750\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 0s 347us/step - loss: 1.6866 - acc: 0.3122 - val_loss: 1.5525 - val_acc: 0.4000\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 0s 358us/step - loss: 1.5964 - acc: 0.3204 - val_loss: 1.4906 - val_acc: 0.4000\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 0s 351us/step - loss: 1.5194 - acc: 0.3260 - val_loss: 1.4403 - val_acc: 0.3750\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 0s 351us/step - loss: 1.4557 - acc: 0.3149 - val_loss: 1.3983 - val_acc: 0.4000\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 0s 368us/step - loss: 1.4031 - acc: 0.3177 - val_loss: 1.3636 - val_acc: 0.4500\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 0s 270us/step - loss: 1.3582 - acc: 0.3287 - val_loss: 1.3329 - val_acc: 0.4250\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 0s 225us/step - loss: 1.3210 - acc: 0.3287 - val_loss: 1.3037 - val_acc: 0.4250\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 0s 227us/step - loss: 1.2890 - acc: 0.3425 - val_loss: 1.2797 - val_acc: 0.4250\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 0s 266us/step - loss: 1.2627 - acc: 0.3508 - val_loss: 1.2588 - val_acc: 0.4500\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 0s 235us/step - loss: 1.2405 - acc: 0.3564 - val_loss: 1.2400 - val_acc: 0.4500\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 0s 223us/step - loss: 1.2211 - acc: 0.3564 - val_loss: 1.2246 - val_acc: 0.4500\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 0s 224us/step - loss: 1.2040 - acc: 0.3674 - val_loss: 1.2116 - val_acc: 0.4500\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 0s 228us/step - loss: 1.1892 - acc: 0.3702 - val_loss: 1.1977 - val_acc: 0.4750\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 0s 206us/step - loss: 1.1760 - acc: 0.3674 - val_loss: 1.1876 - val_acc: 0.4500\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 0s 246us/step - loss: 1.1643 - acc: 0.3840 - val_loss: 1.1775 - val_acc: 0.4750\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 0s 227us/step - loss: 1.1534 - acc: 0.3923 - val_loss: 1.1688 - val_acc: 0.4750\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 0s 231us/step - loss: 1.1441 - acc: 0.3950 - val_loss: 1.1616 - val_acc: 0.4250\n",
      "Epoch 19/20\n",
      "362/362 [==============================] - 0s 237us/step - loss: 1.1354 - acc: 0.4006 - val_loss: 1.1539 - val_acc: 0.4250\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 0s 229us/step - loss: 1.1273 - acc: 0.4144 - val_loss: 1.1485 - val_acc: 0.4000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.1484870433807373\n",
      "Test accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 3\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 10\n",
      "Train on 360 samples, validate on 42 samples\n",
      "Epoch 1/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 1.4569 - acc: 0.2972 - val_loss: 1.4082 - val_acc: 0.3571\n",
      "Epoch 2/20\n",
      "360/360 [==============================] - 0s 290us/step - loss: 1.3820 - acc: 0.3111 - val_loss: 1.3478 - val_acc: 0.3095\n",
      "Epoch 3/20\n",
      "360/360 [==============================] - 0s 264us/step - loss: 1.3265 - acc: 0.3139 - val_loss: 1.2979 - val_acc: 0.3095\n",
      "Epoch 4/20\n",
      "360/360 [==============================] - 0s 234us/step - loss: 1.2820 - acc: 0.3278 - val_loss: 1.2627 - val_acc: 0.2857\n",
      "Epoch 5/20\n",
      "360/360 [==============================] - 0s 278us/step - loss: 1.2505 - acc: 0.3361 - val_loss: 1.2378 - val_acc: 0.2857\n",
      "Epoch 6/20\n",
      "360/360 [==============================] - 0s 320us/step - loss: 1.2254 - acc: 0.3389 - val_loss: 1.2200 - val_acc: 0.3095\n",
      "Epoch 7/20\n",
      "360/360 [==============================] - 0s 322us/step - loss: 1.2041 - acc: 0.3472 - val_loss: 1.2029 - val_acc: 0.3095\n",
      "Epoch 8/20\n",
      "360/360 [==============================] - 0s 236us/step - loss: 1.1857 - acc: 0.3556 - val_loss: 1.1921 - val_acc: 0.3095\n",
      "Epoch 9/20\n",
      "360/360 [==============================] - 0s 425us/step - loss: 1.1699 - acc: 0.3583 - val_loss: 1.1817 - val_acc: 0.2857\n",
      "Epoch 10/20\n",
      "360/360 [==============================] - 0s 322us/step - loss: 1.1567 - acc: 0.3556 - val_loss: 1.1738 - val_acc: 0.2857\n",
      "Epoch 11/20\n",
      "360/360 [==============================] - 0s 279us/step - loss: 1.1451 - acc: 0.3556 - val_loss: 1.1676 - val_acc: 0.2857\n",
      "Epoch 12/20\n",
      "360/360 [==============================] - 0s 279us/step - loss: 1.1353 - acc: 0.3806 - val_loss: 1.1630 - val_acc: 0.2857\n",
      "Epoch 13/20\n",
      "360/360 [==============================] - 0s 234us/step - loss: 1.1269 - acc: 0.3667 - val_loss: 1.1580 - val_acc: 0.2857\n",
      "Epoch 14/20\n",
      "360/360 [==============================] - 0s 322us/step - loss: 1.1191 - acc: 0.3694 - val_loss: 1.1539 - val_acc: 0.2857\n",
      "Epoch 15/20\n",
      "360/360 [==============================] - 0s 427us/step - loss: 1.1125 - acc: 0.3889 - val_loss: 1.1507 - val_acc: 0.2857\n",
      "Epoch 16/20\n",
      "360/360 [==============================] - 0s 234us/step - loss: 1.1065 - acc: 0.3889 - val_loss: 1.1484 - val_acc: 0.3095\n",
      "Epoch 17/20\n",
      "360/360 [==============================] - 0s 365us/step - loss: 1.1013 - acc: 0.3806 - val_loss: 1.1461 - val_acc: 0.3095\n",
      "Epoch 18/20\n",
      "360/360 [==============================] - 0s 332us/step - loss: 1.0968 - acc: 0.3861 - val_loss: 1.1440 - val_acc: 0.3333\n",
      "Epoch 19/20\n",
      "360/360 [==============================] - 0s 311us/step - loss: 1.0922 - acc: 0.3972 - val_loss: 1.1408 - val_acc: 0.3571\n",
      "Epoch 20/20\n",
      "360/360 [==============================] - 0s 381us/step - loss: 1.0883 - acc: 0.4056 - val_loss: 1.1386 - val_acc: 0.3571\n",
      "Running Fold 2 / 10\n",
      "Train on 360 samples, validate on 42 samples\n",
      "Epoch 1/20\n",
      "360/360 [==============================] - 1s 3ms/step - loss: 1.4147 - acc: 0.3083 - val_loss: 1.2480 - val_acc: 0.3095\n",
      "Epoch 2/20\n",
      "360/360 [==============================] - 0s 279us/step - loss: 1.3558 - acc: 0.3167 - val_loss: 1.2166 - val_acc: 0.3095\n",
      "Epoch 3/20\n",
      "360/360 [==============================] - 0s 242us/step - loss: 1.3084 - acc: 0.3361 - val_loss: 1.1911 - val_acc: 0.3333\n",
      "Epoch 4/20\n",
      "360/360 [==============================] - 0s 265us/step - loss: 1.2706 - acc: 0.3528 - val_loss: 1.1724 - val_acc: 0.3571\n",
      "Epoch 5/20\n",
      "360/360 [==============================] - 0s 607us/step - loss: 1.2405 - acc: 0.3722 - val_loss: 1.1559 - val_acc: 0.3810\n",
      "Epoch 6/20\n",
      "360/360 [==============================] - 0s 327us/step - loss: 1.2157 - acc: 0.3806 - val_loss: 1.1441 - val_acc: 0.4048\n",
      "Epoch 7/20\n",
      "360/360 [==============================] - 0s 234us/step - loss: 1.1955 - acc: 0.3694 - val_loss: 1.1344 - val_acc: 0.4048\n",
      "Epoch 8/20\n",
      "360/360 [==============================] - 0s 322us/step - loss: 1.1780 - acc: 0.3889 - val_loss: 1.1259 - val_acc: 0.4286\n",
      "Epoch 9/20\n",
      "360/360 [==============================] - 0s 451us/step - loss: 1.1626 - acc: 0.3889 - val_loss: 1.1187 - val_acc: 0.4048\n",
      "Epoch 10/20\n",
      "360/360 [==============================] - 0s 340us/step - loss: 1.1493 - acc: 0.3861 - val_loss: 1.1143 - val_acc: 0.4048\n",
      "Epoch 11/20\n",
      "360/360 [==============================] - 0s 321us/step - loss: 1.1394 - acc: 0.3944 - val_loss: 1.1105 - val_acc: 0.3810\n",
      "Epoch 12/20\n",
      "360/360 [==============================] - 0s 234us/step - loss: 1.1295 - acc: 0.3917 - val_loss: 1.1059 - val_acc: 0.3810\n",
      "Epoch 13/20\n",
      "360/360 [==============================] - 0s 408us/step - loss: 1.1211 - acc: 0.3944 - val_loss: 1.1022 - val_acc: 0.3810\n",
      "Epoch 14/20\n",
      "360/360 [==============================] - 0s 323us/step - loss: 1.1140 - acc: 0.4056 - val_loss: 1.0997 - val_acc: 0.4048\n",
      "Epoch 15/20\n",
      "360/360 [==============================] - 0s 382us/step - loss: 1.1080 - acc: 0.4083 - val_loss: 1.0988 - val_acc: 0.4048\n",
      "Epoch 16/20\n",
      "360/360 [==============================] - 0s 278us/step - loss: 1.1026 - acc: 0.4194 - val_loss: 1.0982 - val_acc: 0.3810\n",
      "Epoch 17/20\n",
      "360/360 [==============================] - 0s 322us/step - loss: 1.0979 - acc: 0.4250 - val_loss: 1.0964 - val_acc: 0.3810\n",
      "Epoch 18/20\n",
      "360/360 [==============================] - 0s 408us/step - loss: 1.0932 - acc: 0.4250 - val_loss: 1.0967 - val_acc: 0.3810\n",
      "Epoch 19/20\n",
      "360/360 [==============================] - 0s 426us/step - loss: 1.0896 - acc: 0.4333 - val_loss: 1.0962 - val_acc: 0.3810\n",
      "Epoch 20/20\n",
      "360/360 [==============================] - 0s 278us/step - loss: 1.0855 - acc: 0.4417 - val_loss: 1.0946 - val_acc: 0.4048\n",
      "Running Fold 3 / 10\n",
      "Train on 361 samples, validate on 41 samples\n",
      "Epoch 1/20\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 1.2393 - acc: 0.3380 - val_loss: 1.2516 - val_acc: 0.2683\n",
      "Epoch 2/20\n",
      "361/361 [==============================] - 0s 363us/step - loss: 1.2144 - acc: 0.3324 - val_loss: 1.2317 - val_acc: 0.2683\n",
      "Epoch 3/20\n",
      "361/361 [==============================] - 0s 279us/step - loss: 1.1944 - acc: 0.3463 - val_loss: 1.2149 - val_acc: 0.2927\n",
      "Epoch 4/20\n",
      "361/361 [==============================] - 0s 363us/step - loss: 1.1780 - acc: 0.3546 - val_loss: 1.2029 - val_acc: 0.3171\n",
      "Epoch 5/20\n",
      "361/361 [==============================] - 0s 339us/step - loss: 1.1648 - acc: 0.3657 - val_loss: 1.1930 - val_acc: 0.2927\n",
      "Epoch 6/20\n",
      "361/361 [==============================] - 0s 276us/step - loss: 1.1533 - acc: 0.3684 - val_loss: 1.1830 - val_acc: 0.3415\n",
      "Epoch 7/20\n",
      "361/361 [==============================] - 0s 277us/step - loss: 1.1435 - acc: 0.3712 - val_loss: 1.1745 - val_acc: 0.3415\n",
      "Epoch 8/20\n",
      "361/361 [==============================] - 0s 364us/step - loss: 1.1352 - acc: 0.3740 - val_loss: 1.1647 - val_acc: 0.3659\n",
      "Epoch 9/20\n",
      "361/361 [==============================] - 0s 278us/step - loss: 1.1277 - acc: 0.3795 - val_loss: 1.1583 - val_acc: 0.3659\n",
      "Epoch 10/20\n",
      "361/361 [==============================] - 0s 234us/step - loss: 1.1210 - acc: 0.3961 - val_loss: 1.1525 - val_acc: 0.3659\n",
      "Epoch 11/20\n",
      "361/361 [==============================] - 0s 233us/step - loss: 1.1150 - acc: 0.3961 - val_loss: 1.1477 - val_acc: 0.3902\n",
      "Epoch 12/20\n",
      "361/361 [==============================] - 0s 173us/step - loss: 1.1099 - acc: 0.4072 - val_loss: 1.1419 - val_acc: 0.4146\n",
      "Epoch 13/20\n",
      "361/361 [==============================] - 0s 426us/step - loss: 1.1048 - acc: 0.4100 - val_loss: 1.1364 - val_acc: 0.4146\n",
      "Epoch 14/20\n",
      "361/361 [==============================] - 0s 363us/step - loss: 1.1003 - acc: 0.4238 - val_loss: 1.1311 - val_acc: 0.4146\n",
      "Epoch 15/20\n",
      "361/361 [==============================] - 0s 233us/step - loss: 1.0968 - acc: 0.4183 - val_loss: 1.1271 - val_acc: 0.4390\n",
      "Epoch 16/20\n",
      "361/361 [==============================] - 0s 424us/step - loss: 1.0931 - acc: 0.4238 - val_loss: 1.1222 - val_acc: 0.4146\n",
      "Epoch 17/20\n",
      "361/361 [==============================] - 0s 365us/step - loss: 1.0899 - acc: 0.4211 - val_loss: 1.1185 - val_acc: 0.4146\n",
      "Epoch 18/20\n",
      "361/361 [==============================] - 0s 320us/step - loss: 1.0871 - acc: 0.4266 - val_loss: 1.1156 - val_acc: 0.4146\n",
      "Epoch 19/20\n",
      "361/361 [==============================] - 0s 469us/step - loss: 1.0843 - acc: 0.4183 - val_loss: 1.1116 - val_acc: 0.4146\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 278us/step - loss: 1.0819 - acc: 0.4211 - val_loss: 1.1106 - val_acc: 0.4146\n",
      "Running Fold 4 / 10\n",
      "Train on 361 samples, validate on 41 samples\n",
      "Epoch 1/20\n",
      "361/361 [==============================] - 1s 3ms/step - loss: 1.4909 - acc: 0.3213 - val_loss: 1.3808 - val_acc: 0.3415\n",
      "Epoch 2/20\n",
      "361/361 [==============================] - 0s 511us/step - loss: 1.3758 - acc: 0.3269 - val_loss: 1.2832 - val_acc: 0.3659\n",
      "Epoch 3/20\n",
      "361/361 [==============================] - 0s 555us/step - loss: 1.2890 - acc: 0.3269 - val_loss: 1.2252 - val_acc: 0.3659\n",
      "Epoch 4/20\n",
      "361/361 [==============================] - 0s 511us/step - loss: 1.2338 - acc: 0.3463 - val_loss: 1.1895 - val_acc: 0.3415\n",
      "Epoch 5/20\n",
      "361/361 [==============================] - 0s 511us/step - loss: 1.1982 - acc: 0.3518 - val_loss: 1.1672 - val_acc: 0.4146\n",
      "Epoch 6/20\n",
      "361/361 [==============================] - 0s 555us/step - loss: 1.1739 - acc: 0.3629 - val_loss: 1.1520 - val_acc: 0.4634\n",
      "Epoch 7/20\n",
      "361/361 [==============================] - 0s 406us/step - loss: 1.1565 - acc: 0.3573 - val_loss: 1.1406 - val_acc: 0.4390\n",
      "Epoch 8/20\n",
      "361/361 [==============================] - 0s 338us/step - loss: 1.1439 - acc: 0.3684 - val_loss: 1.1308 - val_acc: 0.4634\n",
      "Epoch 9/20\n",
      "361/361 [==============================] - 0s 320us/step - loss: 1.1338 - acc: 0.3795 - val_loss: 1.1225 - val_acc: 0.4146\n",
      "Epoch 10/20\n",
      "361/361 [==============================] - 0s 407us/step - loss: 1.1243 - acc: 0.3850 - val_loss: 1.1161 - val_acc: 0.4146\n",
      "Epoch 11/20\n",
      "361/361 [==============================] - 0s 369us/step - loss: 1.1174 - acc: 0.3934 - val_loss: 1.1098 - val_acc: 0.4146\n",
      "Epoch 12/20\n",
      "361/361 [==============================] - 0s 284us/step - loss: 1.1109 - acc: 0.3934 - val_loss: 1.1039 - val_acc: 0.4390\n",
      "Epoch 13/20\n",
      "361/361 [==============================] - 0s 217us/step - loss: 1.1050 - acc: 0.3906 - val_loss: 1.0990 - val_acc: 0.4390\n",
      "Epoch 14/20\n",
      "361/361 [==============================] - 0s 426us/step - loss: 1.1011 - acc: 0.3961 - val_loss: 1.0945 - val_acc: 0.4146\n",
      "Epoch 15/20\n",
      "361/361 [==============================] - 0s 321us/step - loss: 1.0963 - acc: 0.3934 - val_loss: 1.0918 - val_acc: 0.4146\n",
      "Epoch 16/20\n",
      "361/361 [==============================] - 0s 364us/step - loss: 1.0925 - acc: 0.4044 - val_loss: 1.0886 - val_acc: 0.3902\n",
      "Epoch 17/20\n",
      "361/361 [==============================] - 0s 278us/step - loss: 1.0889 - acc: 0.3961 - val_loss: 1.0856 - val_acc: 0.4146\n",
      "Epoch 18/20\n",
      "361/361 [==============================] - 0s 380us/step - loss: 1.0855 - acc: 0.4100 - val_loss: 1.0832 - val_acc: 0.3902\n",
      "Epoch 19/20\n",
      "361/361 [==============================] - 0s 407us/step - loss: 1.0830 - acc: 0.4155 - val_loss: 1.0808 - val_acc: 0.3902\n",
      "Epoch 20/20\n",
      "361/361 [==============================] - 0s 338us/step - loss: 1.0802 - acc: 0.4155 - val_loss: 1.0796 - val_acc: 0.3902\n",
      "Running Fold 5 / 10\n",
      "Train on 362 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 1.5135 - acc: 0.3757 - val_loss: 1.4959 - val_acc: 0.3250\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 0s 449us/step - loss: 1.4390 - acc: 0.3923 - val_loss: 1.4579 - val_acc: 0.3000\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 0s 381us/step - loss: 1.3826 - acc: 0.3923 - val_loss: 1.4299 - val_acc: 0.3250\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 0s 319us/step - loss: 1.3396 - acc: 0.4006 - val_loss: 1.4054 - val_acc: 0.3000\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 0s 362us/step - loss: 1.3052 - acc: 0.3923 - val_loss: 1.3855 - val_acc: 0.2500\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 0s 276us/step - loss: 1.2780 - acc: 0.3978 - val_loss: 1.3690 - val_acc: 0.2500\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 0s 596us/step - loss: 1.2536 - acc: 0.4033 - val_loss: 1.3537 - val_acc: 0.2750\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 0s 381us/step - loss: 1.2330 - acc: 0.4061 - val_loss: 1.3407 - val_acc: 0.2750\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 0s 362us/step - loss: 1.2147 - acc: 0.4061 - val_loss: 1.3262 - val_acc: 0.3000\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 0s 365us/step - loss: 1.1986 - acc: 0.4006 - val_loss: 1.3130 - val_acc: 0.2750\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 0s 277us/step - loss: 1.1838 - acc: 0.4006 - val_loss: 1.3002 - val_acc: 0.2750\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 0s 368us/step - loss: 1.1701 - acc: 0.4006 - val_loss: 1.2887 - val_acc: 0.2500\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 0s 285us/step - loss: 1.1588 - acc: 0.4116 - val_loss: 1.2791 - val_acc: 0.2500\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 0s 263us/step - loss: 1.1473 - acc: 0.4116 - val_loss: 1.2706 - val_acc: 0.2750\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 0s 228us/step - loss: 1.1371 - acc: 0.4254 - val_loss: 1.2621 - val_acc: 0.2750\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 0s 380us/step - loss: 1.1276 - acc: 0.4199 - val_loss: 1.2559 - val_acc: 0.3000\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 0s 554us/step - loss: 1.1195 - acc: 0.4227 - val_loss: 1.2482 - val_acc: 0.3250\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 0s 407us/step - loss: 1.1112 - acc: 0.4254 - val_loss: 1.2423 - val_acc: 0.3250\n",
      "Epoch 19/20\n",
      "362/362 [==============================] - 0s 380us/step - loss: 1.1038 - acc: 0.4337 - val_loss: 1.2378 - val_acc: 0.3250\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 0s 362us/step - loss: 1.0972 - acc: 0.4309 - val_loss: 1.2360 - val_acc: 0.3500\n",
      "Running Fold 6 / 10\n",
      "Train on 362 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 1.4772 - acc: 0.3177 - val_loss: 1.5516 - val_acc: 0.3000\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 0s 362us/step - loss: 1.4246 - acc: 0.3232 - val_loss: 1.5109 - val_acc: 0.3000\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 0s 424us/step - loss: 1.3790 - acc: 0.3204 - val_loss: 1.4746 - val_acc: 0.3500\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 0s 498us/step - loss: 1.3401 - acc: 0.3370 - val_loss: 1.4435 - val_acc: 0.4250\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 0s 332us/step - loss: 1.3084 - acc: 0.3481 - val_loss: 1.4163 - val_acc: 0.3750\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 0s 362us/step - loss: 1.2802 - acc: 0.3564 - val_loss: 1.3937 - val_acc: 0.4000\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 0s 319us/step - loss: 1.2565 - acc: 0.3564 - val_loss: 1.3718 - val_acc: 0.4000\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 0s 276us/step - loss: 1.2355 - acc: 0.3508 - val_loss: 1.3526 - val_acc: 0.4000\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 0s 375us/step - loss: 1.2166 - acc: 0.3619 - val_loss: 1.3343 - val_acc: 0.4000\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 0s 323us/step - loss: 1.1997 - acc: 0.3591 - val_loss: 1.3179 - val_acc: 0.3750\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 0s 362us/step - loss: 1.1852 - acc: 0.3646 - val_loss: 1.3030 - val_acc: 0.4000\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 0s 423us/step - loss: 1.1717 - acc: 0.3702 - val_loss: 1.2889 - val_acc: 0.4250\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 0s 407us/step - loss: 1.1603 - acc: 0.3702 - val_loss: 1.2756 - val_acc: 0.4500\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 0s 414us/step - loss: 1.1495 - acc: 0.3757 - val_loss: 1.2628 - val_acc: 0.4250\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 0s 457us/step - loss: 1.1407 - acc: 0.3840 - val_loss: 1.2524 - val_acc: 0.4000\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 0s 235us/step - loss: 1.1326 - acc: 0.3923 - val_loss: 1.2429 - val_acc: 0.4250\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 0s 363us/step - loss: 1.1250 - acc: 0.3923 - val_loss: 1.2332 - val_acc: 0.4000\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 0s 510us/step - loss: 1.1191 - acc: 0.3978 - val_loss: 1.2238 - val_acc: 0.4000\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 0s 319us/step - loss: 1.1129 - acc: 0.4006 - val_loss: 1.2157 - val_acc: 0.4000\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 0s 320us/step - loss: 1.1074 - acc: 0.3978 - val_loss: 1.2080 - val_acc: 0.4000\n",
      "Running Fold 7 / 10\n",
      "Train on 363 samples, validate on 39 samples\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3905 - acc: 0.3306 - val_loss: 1.3780 - val_acc: 0.3333\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 447us/step - loss: 1.3461 - acc: 0.3444 - val_loss: 1.3381 - val_acc: 0.3333\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 554us/step - loss: 1.3110 - acc: 0.3499 - val_loss: 1.3055 - val_acc: 0.3590\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 464us/step - loss: 1.2815 - acc: 0.3471 - val_loss: 1.2779 - val_acc: 0.3590\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 422us/step - loss: 1.2564 - acc: 0.3278 - val_loss: 1.2555 - val_acc: 0.4359\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.2353 - acc: 0.3526 - val_loss: 1.2351 - val_acc: 0.4359\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 361us/step - loss: 1.2168 - acc: 0.3609 - val_loss: 1.2177 - val_acc: 0.4615\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 379us/step - loss: 1.2008 - acc: 0.3747 - val_loss: 1.2016 - val_acc: 0.4615\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 320us/step - loss: 1.1862 - acc: 0.3829 - val_loss: 1.1877 - val_acc: 0.4615\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.1739 - acc: 0.3884 - val_loss: 1.1748 - val_acc: 0.4615\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 276us/step - loss: 1.1622 - acc: 0.3857 - val_loss: 1.1633 - val_acc: 0.4615\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 318us/step - loss: 1.1515 - acc: 0.3884 - val_loss: 1.1540 - val_acc: 0.4359\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 361us/step - loss: 1.1423 - acc: 0.3912 - val_loss: 1.1451 - val_acc: 0.4359\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 378us/step - loss: 1.1337 - acc: 0.3939 - val_loss: 1.1367 - val_acc: 0.4359\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 361us/step - loss: 1.1260 - acc: 0.3994 - val_loss: 1.1297 - val_acc: 0.4359\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 278us/step - loss: 1.1195 - acc: 0.3857 - val_loss: 1.1229 - val_acc: 0.4359\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 360us/step - loss: 1.1133 - acc: 0.3939 - val_loss: 1.1165 - val_acc: 0.4103\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 421us/step - loss: 1.1081 - acc: 0.3912 - val_loss: 1.1115 - val_acc: 0.3846\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 447us/step - loss: 1.1031 - acc: 0.3912 - val_loss: 1.1067 - val_acc: 0.4103\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 337us/step - loss: 1.0994 - acc: 0.3857 - val_loss: 1.1030 - val_acc: 0.4103\n",
      "Running Fold 8 / 10\n",
      "Train on 363 samples, validate on 39 samples\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3994 - acc: 0.3113 - val_loss: 1.2838 - val_acc: 0.3590\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.2903 - acc: 0.3196 - val_loss: 1.2499 - val_acc: 0.3846\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 276us/step - loss: 1.2189 - acc: 0.3333 - val_loss: 1.2334 - val_acc: 0.3846\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 464us/step - loss: 1.1761 - acc: 0.3361 - val_loss: 1.2237 - val_acc: 0.3590\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 222us/step - loss: 1.1493 - acc: 0.3471 - val_loss: 1.2182 - val_acc: 0.3846\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 264us/step - loss: 1.1307 - acc: 0.3747 - val_loss: 1.2143 - val_acc: 0.3846\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 232us/step - loss: 1.1192 - acc: 0.3747 - val_loss: 1.2100 - val_acc: 0.4359\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.1092 - acc: 0.3774 - val_loss: 1.2049 - val_acc: 0.4359\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 422us/step - loss: 1.1023 - acc: 0.3719 - val_loss: 1.1999 - val_acc: 0.4615\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 361us/step - loss: 1.0964 - acc: 0.3747 - val_loss: 1.1940 - val_acc: 0.4103\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.0920 - acc: 0.3664 - val_loss: 1.1887 - val_acc: 0.3846\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 422us/step - loss: 1.0880 - acc: 0.3609 - val_loss: 1.1828 - val_acc: 0.3846\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 361us/step - loss: 1.0842 - acc: 0.3802 - val_loss: 1.1767 - val_acc: 0.4103\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 299us/step - loss: 1.0812 - acc: 0.3774 - val_loss: 1.1722 - val_acc: 0.3846\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 484us/step - loss: 1.0783 - acc: 0.3967 - val_loss: 1.1656 - val_acc: 0.4103\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 277us/step - loss: 1.0759 - acc: 0.3994 - val_loss: 1.1608 - val_acc: 0.4103\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 404us/step - loss: 1.0740 - acc: 0.3857 - val_loss: 1.1566 - val_acc: 0.4103\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 465us/step - loss: 1.0723 - acc: 0.3994 - val_loss: 1.1519 - val_acc: 0.4103\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 189us/step - loss: 1.0701 - acc: 0.3939 - val_loss: 1.1473 - val_acc: 0.4359\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 361us/step - loss: 1.0687 - acc: 0.3884 - val_loss: 1.1427 - val_acc: 0.4103\n",
      "Running Fold 9 / 10\n",
      "Train on 363 samples, validate on 39 samples\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.7070 - acc: 0.3361 - val_loss: 1.7875 - val_acc: 0.2821\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.6062 - acc: 0.3278 - val_loss: 1.6894 - val_acc: 0.2308\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 363us/step - loss: 1.5197 - acc: 0.3416 - val_loss: 1.6048 - val_acc: 0.2308\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.4456 - acc: 0.3499 - val_loss: 1.5305 - val_acc: 0.2564\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 319us/step - loss: 1.3812 - acc: 0.3691 - val_loss: 1.4683 - val_acc: 0.2564\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 318us/step - loss: 1.3275 - acc: 0.3774 - val_loss: 1.4166 - val_acc: 0.2564\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 423us/step - loss: 1.2832 - acc: 0.3884 - val_loss: 1.3724 - val_acc: 0.2564\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 361us/step - loss: 1.2460 - acc: 0.3719 - val_loss: 1.3362 - val_acc: 0.2821\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 378us/step - loss: 1.2163 - acc: 0.3857 - val_loss: 1.3056 - val_acc: 0.3077\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 318us/step - loss: 1.1917 - acc: 0.3829 - val_loss: 1.2794 - val_acc: 0.3333\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 362us/step - loss: 1.1725 - acc: 0.3912 - val_loss: 1.2591 - val_acc: 0.3333\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 412us/step - loss: 1.1565 - acc: 0.3967 - val_loss: 1.2394 - val_acc: 0.3333\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 371us/step - loss: 1.1421 - acc: 0.3967 - val_loss: 1.2239 - val_acc: 0.3333\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.1307 - acc: 0.3967 - val_loss: 1.2084 - val_acc: 0.3333\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 362us/step - loss: 1.1213 - acc: 0.3994 - val_loss: 1.1961 - val_acc: 0.3333\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 390us/step - loss: 1.1126 - acc: 0.4132 - val_loss: 1.1852 - val_acc: 0.3333\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 219us/step - loss: 1.1054 - acc: 0.4242 - val_loss: 1.1752 - val_acc: 0.3333\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 408us/step - loss: 1.0989 - acc: 0.4215 - val_loss: 1.1653 - val_acc: 0.3333\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.0937 - acc: 0.4270 - val_loss: 1.1563 - val_acc: 0.3333\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 276us/step - loss: 1.0888 - acc: 0.4463 - val_loss: 1.1486 - val_acc: 0.3590\n",
      "Running Fold 10 / 10\n",
      "Train on 363 samples, validate on 39 samples\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3312 - acc: 0.3912 - val_loss: 1.3676 - val_acc: 0.3846\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 275us/step - loss: 1.2816 - acc: 0.3884 - val_loss: 1.3276 - val_acc: 0.3846\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 406us/step - loss: 1.2431 - acc: 0.3829 - val_loss: 1.2974 - val_acc: 0.3590\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 464us/step - loss: 1.2135 - acc: 0.3939 - val_loss: 1.2723 - val_acc: 0.3590\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 456us/step - loss: 1.1888 - acc: 0.3967 - val_loss: 1.2525 - val_acc: 0.3590\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 280us/step - loss: 1.1700 - acc: 0.4077 - val_loss: 1.2362 - val_acc: 0.3590\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 448us/step - loss: 1.1544 - acc: 0.4132 - val_loss: 1.2224 - val_acc: 0.3590\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 507us/step - loss: 1.1416 - acc: 0.4298 - val_loss: 1.2114 - val_acc: 0.3590\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 465us/step - loss: 1.1309 - acc: 0.4215 - val_loss: 1.2023 - val_acc: 0.3590\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 232us/step - loss: 1.1220 - acc: 0.4270 - val_loss: 1.1943 - val_acc: 0.3590\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 277us/step - loss: 1.1145 - acc: 0.4215 - val_loss: 1.1880 - val_acc: 0.3846\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 318us/step - loss: 1.1079 - acc: 0.4160 - val_loss: 1.1830 - val_acc: 0.3846\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 404us/step - loss: 1.1017 - acc: 0.4187 - val_loss: 1.1783 - val_acc: 0.3846\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 276us/step - loss: 1.0965 - acc: 0.4160 - val_loss: 1.1742 - val_acc: 0.3846\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 318us/step - loss: 1.0920 - acc: 0.4270 - val_loss: 1.1698 - val_acc: 0.3590\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 338us/step - loss: 1.0876 - acc: 0.4270 - val_loss: 1.1664 - val_acc: 0.3590\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 360us/step - loss: 1.0843 - acc: 0.4353 - val_loss: 1.1638 - val_acc: 0.3590\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 233us/step - loss: 1.0811 - acc: 0.4298 - val_loss: 1.1607 - val_acc: 0.3590\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 318us/step - loss: 1.0780 - acc: 0.4325 - val_loss: 1.1587 - val_acc: 0.3590\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 404us/step - loss: 1.0757 - acc: 0.4242 - val_loss: 1.1568 - val_acc: 0.3846\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "\n",
    "labels = df['flow_rate'].values\n",
    "data = x\n",
    "\n",
    "labels[labels == 1800] = 0\n",
    "labels[labels == 3600] = 1\n",
    "labels[labels == 7200] = 2\n",
    "\n",
    "labels = np_utils.to_categorical(labels, nb_classes) \n",
    "\n",
    "skf = StratifiedKFold(df['flow_rate'].values, n_folds=n_folds, shuffle=True)\n",
    "avg_acc = 0\n",
    "\n",
    "for i, (train, test) in enumerate(skf):\n",
    "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    model = None # Clearing the NN.\n",
    "    model = build_logistic_model(input_dim, nb_classes)\n",
    "    avg_acc += train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score:  0.38808853851938646\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Score: \", avg_acc/n_folds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
