{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment\n",
    "# experiment = Experiment(api_key=\"xktj4EX0zB8YcQ3BEaFwOQYpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duo\\Anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\train\\\\\"\n",
    "train_csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\train\\\\ids.csv\"\n",
    "test_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\test\\\\\"\n",
    "test_csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\test\\\\ids.csv\"\n",
    "\n",
    "dest_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\\"\n",
    "\n",
    "csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\ids.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv,index_col=0).sample(frac=1)\n",
    "\n",
    "df['log_volume'] = df['volume'].apply(np.log)\n",
    "\n",
    "x = df.drop(columns=['name','date','flow_rate','source','moments','inertia_tensor'])\n",
    "# x = standardize = preprocessing.scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>flow_rate</th>\n",
       "      <th>source</th>\n",
       "      <th>peak_val</th>\n",
       "      <th>area</th>\n",
       "      <th>volume</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>euler_number</th>\n",
       "      <th>extent</th>\n",
       "      <th>mean_intensity</th>\n",
       "      <th>moments</th>\n",
       "      <th>orientation</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>inertia_tensor</th>\n",
       "      <th>cluster</th>\n",
       "      <th>num_peaks</th>\n",
       "      <th>log_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>2017.11.22</td>\n",
       "      <td>7200</td>\n",
       "      <td>35.80 s.tifheightmap.mat</td>\n",
       "      <td>4.854192</td>\n",
       "      <td>2055</td>\n",
       "      <td>5440.452402</td>\n",
       "      <td>0.946396</td>\n",
       "      <td>1</td>\n",
       "      <td>0.368544</td>\n",
       "      <td>2.647422</td>\n",
       "      <td>[[2.05500000e+03 9.37710000e+04 5.11496900e+06...</td>\n",
       "      <td>0.886416</td>\n",
       "      <td>236.835570</td>\n",
       "      <td>[[292.97894613 278.03612482]\\r\\n [278.03612482...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.601617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2017.11.17</td>\n",
       "      <td>3600</td>\n",
       "      <td>1.25 s.tifheightmap.mat</td>\n",
       "      <td>8.839536</td>\n",
       "      <td>1234</td>\n",
       "      <td>6886.017413</td>\n",
       "      <td>0.489669</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>5.544297</td>\n",
       "      <td>[[1.24200000e+03 3.03310000e+04 8.91325000e+05...</td>\n",
       "      <td>1.298008</td>\n",
       "      <td>144.953319</td>\n",
       "      <td>[[ 95.96786714   7.6775466 ]\\r\\n [  7.6775466 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.837248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12_flipped</td>\n",
       "      <td>2017.11.09</td>\n",
       "      <td>3600</td>\n",
       "      <td>chip3_03heightmap.mat</td>\n",
       "      <td>12.532234</td>\n",
       "      <td>4756</td>\n",
       "      <td>38034.038483</td>\n",
       "      <td>0.756339</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717995</td>\n",
       "      <td>7.997064</td>\n",
       "      <td>[[4.75600000e+03 2.31341000e+05 1.38869750e+07...</td>\n",
       "      <td>1.199091</td>\n",
       "      <td>292.693434</td>\n",
       "      <td>[[301.57312913 115.9663349 ]\\r\\n [115.9663349 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.546237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>84_flipped</td>\n",
       "      <td>2017.11.22</td>\n",
       "      <td>1800</td>\n",
       "      <td>44.60 s.tifheightmap.mat</td>\n",
       "      <td>21.427335</td>\n",
       "      <td>2675</td>\n",
       "      <td>23258.006678</td>\n",
       "      <td>0.921300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422992</td>\n",
       "      <td>8.694582</td>\n",
       "      <td>[[2.67500000e+03 1.34857000e+05 8.05168900e+06...</td>\n",
       "      <td>-0.940939</td>\n",
       "      <td>291.279221</td>\n",
       "      <td>[[ 295.92398288 -268.25541305]\\r\\n [-268.25541...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.054405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>2017.11.17</td>\n",
       "      <td>3600</td>\n",
       "      <td>26.45 s.tifheightmap.mat</td>\n",
       "      <td>4.989847</td>\n",
       "      <td>5936</td>\n",
       "      <td>16831.576998</td>\n",
       "      <td>0.972562</td>\n",
       "      <td>1</td>\n",
       "      <td>0.346972</td>\n",
       "      <td>2.835508</td>\n",
       "      <td>[[5.93600000e+03 6.72046000e+05 9.04600940e+07...</td>\n",
       "      <td>1.213680</td>\n",
       "      <td>497.244733</td>\n",
       "      <td>[[ 464.67299942  848.21577169]\\r\\n [ 848.21577...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.731012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name        date  flow_rate                    source   peak_val  \\\n",
       "120         120  2017.11.22       7200  35.80 s.tifheightmap.mat   4.854192   \n",
       "32           32  2017.11.17       3600   1.25 s.tifheightmap.mat   8.839536   \n",
       "225  12_flipped  2017.11.09       3600     chip3_03heightmap.mat  12.532234   \n",
       "385  84_flipped  2017.11.22       1800  44.60 s.tifheightmap.mat  21.427335   \n",
       "47           47  2017.11.17       3600  26.45 s.tifheightmap.mat   4.989847   \n",
       "\n",
       "     area        volume  eccentricity  euler_number    extent  mean_intensity  \\\n",
       "120  2055   5440.452402      0.946396             1  0.368544        2.647422   \n",
       "32   1234   6886.017413      0.489669             1  0.624434        5.544297   \n",
       "225  4756  38034.038483      0.756339             1  0.717995        7.997064   \n",
       "385  2675  23258.006678      0.921300             1  0.422992        8.694582   \n",
       "47   5936  16831.576998      0.972562             1  0.346972        2.835508   \n",
       "\n",
       "                                               moments  orientation  \\\n",
       "120  [[2.05500000e+03 9.37710000e+04 5.11496900e+06...     0.886416   \n",
       "32   [[1.24200000e+03 3.03310000e+04 8.91325000e+05...     1.298008   \n",
       "225  [[4.75600000e+03 2.31341000e+05 1.38869750e+07...     1.199091   \n",
       "385  [[2.67500000e+03 1.34857000e+05 8.05168900e+06...    -0.940939   \n",
       "47   [[5.93600000e+03 6.72046000e+05 9.04600940e+07...     1.213680   \n",
       "\n",
       "      perimeter                                     inertia_tensor  cluster  \\\n",
       "120  236.835570  [[292.97894613 278.03612482]\\r\\n [278.03612482...        2   \n",
       "32   144.953319  [[ 95.96786714   7.6775466 ]\\r\\n [  7.6775466 ...        0   \n",
       "225  292.693434  [[301.57312913 115.9663349 ]\\r\\n [115.9663349 ...        0   \n",
       "385  291.279221  [[ 295.92398288 -268.25541305]\\r\\n [-268.25541...        0   \n",
       "47   497.244733  [[ 464.67299942  848.21577169]\\r\\n [ 848.21577...        2   \n",
       "\n",
       "     num_peaks  log_volume  \n",
       "120          1    8.601617  \n",
       "32           1    8.837248  \n",
       "225          1   10.546237  \n",
       "385          1   10.054405  \n",
       "47           1    9.731012  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(df.shape[0]/10)\n",
    "\n",
    "x_test = np.array(x[:test_size])\n",
    "y_test = df['flow_rate'][:test_size].values\n",
    "\n",
    "x_train = np.array(x[test_size:])\n",
    "y_train = df['flow_rate'][test_size:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0 ...   0   0 106]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ...,  0,  0, 10], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.bincount(y_train))\n",
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 3\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 1800] = 0\n",
    "y_train[y_train == 3600] = 1\n",
    "y_train[y_train == 7200] = 2\n",
    "\n",
    "y_test[y_test == 1800] = 0\n",
    "y_test[y_test == 3600] = 1\n",
    "y_test[y_test == 7200] = 2\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes) \n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmda = 0.01\n",
    "\n",
    "def build_logistic_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim, input_dim=input_dim,\n",
    "                    kernel_regularizer=l2(lmda),\n",
    "                    activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = build_logistic_model(input_dim, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 39\n",
      "Trainable params: 39\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 362 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "362/362 [==============================] - 4s 10ms/step - loss: 1.3396 - acc: 0.3674 - val_loss: 1.3562 - val_acc: 0.3250\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 0s 319us/step - loss: 1.2704 - acc: 0.3840 - val_loss: 1.3101 - val_acc: 0.3500\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 0s 449us/step - loss: 1.2233 - acc: 0.4006 - val_loss: 1.2745 - val_acc: 0.3500\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 0s 230us/step - loss: 1.1894 - acc: 0.3923 - val_loss: 1.2467 - val_acc: 0.3250\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 0s 276us/step - loss: 1.1643 - acc: 0.3812 - val_loss: 1.2251 - val_acc: 0.3250\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 0s 380us/step - loss: 1.1453 - acc: 0.3757 - val_loss: 1.2080 - val_acc: 0.3250\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 0s 319us/step - loss: 1.1315 - acc: 0.3867 - val_loss: 1.1938 - val_acc: 0.3250\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 0s 277us/step - loss: 1.1195 - acc: 0.3840 - val_loss: 1.1817 - val_acc: 0.3250\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 0s 406us/step - loss: 1.1098 - acc: 0.3950 - val_loss: 1.1718 - val_acc: 0.3250\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 0s 276us/step - loss: 1.1017 - acc: 0.3923 - val_loss: 1.1632 - val_acc: 0.3500\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 0s 329us/step - loss: 1.0950 - acc: 0.3950 - val_loss: 1.1559 - val_acc: 0.4250\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 0s 281us/step - loss: 1.0888 - acc: 0.4033 - val_loss: 1.1507 - val_acc: 0.4250\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 0s 320us/step - loss: 1.0836 - acc: 0.4033 - val_loss: 1.1454 - val_acc: 0.4250\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 0s 319us/step - loss: 1.0793 - acc: 0.4033 - val_loss: 1.1412 - val_acc: 0.4250\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 0s 320us/step - loss: 1.0755 - acc: 0.4116 - val_loss: 1.1372 - val_acc: 0.4250\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 0s 362us/step - loss: 1.0726 - acc: 0.4033 - val_loss: 1.1334 - val_acc: 0.4250\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 0s 424us/step - loss: 1.0688 - acc: 0.4171 - val_loss: 1.1291 - val_acc: 0.4250\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 0s 458us/step - loss: 1.0652 - acc: 0.4171 - val_loss: 1.1261 - val_acc: 0.4250\n",
      "Epoch 19/20\n",
      "362/362 [==============================] - 0s 545us/step - loss: 1.0632 - acc: 0.4088 - val_loss: 1.1234 - val_acc: 0.4250\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 0s 285us/step - loss: 1.0604 - acc: 0.4116 - val_loss: 1.1211 - val_acc: 0.4250\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.1210774540901185\n",
      "Test accuracy: 0.425\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_classes = 3\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 10\n",
      "Train on 360 samples, validate on 42 samples\n",
      "Epoch 1/20\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 1.5124 - acc: 0.3389 - val_loss: 1.4932 - val_acc: 0.2857\n",
      "Epoch 2/20\n",
      "360/360 [==============================] - 0s 393us/step - loss: 1.4232 - acc: 0.3333 - val_loss: 1.3971 - val_acc: 0.2619\n",
      "Epoch 3/20\n",
      "360/360 [==============================] - 0s 371us/step - loss: 1.3596 - acc: 0.3306 - val_loss: 1.3300 - val_acc: 0.3095\n",
      "Epoch 4/20\n",
      "360/360 [==============================] - 0s 363us/step - loss: 1.3130 - acc: 0.3472 - val_loss: 1.2818 - val_acc: 0.3095\n",
      "Epoch 5/20\n",
      "360/360 [==============================] - 0s 396us/step - loss: 1.2782 - acc: 0.3528 - val_loss: 1.2447 - val_acc: 0.2857\n",
      "Epoch 6/20\n",
      "360/360 [==============================] - 0s 382us/step - loss: 1.2496 - acc: 0.3500 - val_loss: 1.2166 - val_acc: 0.3095\n",
      "Epoch 7/20\n",
      "360/360 [==============================] - 0s 342us/step - loss: 1.2273 - acc: 0.3444 - val_loss: 1.1938 - val_acc: 0.3095\n",
      "Epoch 8/20\n",
      "360/360 [==============================] - 0s 281us/step - loss: 1.2083 - acc: 0.3444 - val_loss: 1.1764 - val_acc: 0.2857\n",
      "Epoch 9/20\n",
      "360/360 [==============================] - 0s 279us/step - loss: 1.1932 - acc: 0.3444 - val_loss: 1.1602 - val_acc: 0.2619\n",
      "Epoch 10/20\n",
      "360/360 [==============================] - 0s 295us/step - loss: 1.1801 - acc: 0.3528 - val_loss: 1.1474 - val_acc: 0.2857\n",
      "Epoch 11/20\n",
      "360/360 [==============================] - 0s 259us/step - loss: 1.1691 - acc: 0.3556 - val_loss: 1.1352 - val_acc: 0.2857\n",
      "Epoch 12/20\n",
      "360/360 [==============================] - 0s 285us/step - loss: 1.1585 - acc: 0.3694 - val_loss: 1.1253 - val_acc: 0.3095\n",
      "Epoch 13/20\n",
      "360/360 [==============================] - 0s 275us/step - loss: 1.1500 - acc: 0.3722 - val_loss: 1.1145 - val_acc: 0.3095\n",
      "Epoch 14/20\n",
      "360/360 [==============================] - 0s 263us/step - loss: 1.1430 - acc: 0.3694 - val_loss: 1.1062 - val_acc: 0.3095\n",
      "Epoch 15/20\n",
      "360/360 [==============================] - 0s 278us/step - loss: 1.1360 - acc: 0.3889 - val_loss: 1.0990 - val_acc: 0.3095\n",
      "Epoch 16/20\n",
      "360/360 [==============================] - 0s 268us/step - loss: 1.1301 - acc: 0.3833 - val_loss: 1.0919 - val_acc: 0.3095\n",
      "Epoch 17/20\n",
      "360/360 [==============================] - 0s 300us/step - loss: 1.1252 - acc: 0.4111 - val_loss: 1.0858 - val_acc: 0.3333\n",
      "Epoch 18/20\n",
      "360/360 [==============================] - 0s 256us/step - loss: 1.1203 - acc: 0.3972 - val_loss: 1.0785 - val_acc: 0.3333\n",
      "Epoch 19/20\n",
      "360/360 [==============================] - 0s 300us/step - loss: 1.1160 - acc: 0.4000 - val_loss: 1.0727 - val_acc: 0.3333\n",
      "Epoch 20/20\n",
      "360/360 [==============================] - 0s 264us/step - loss: 1.1119 - acc: 0.4222 - val_loss: 1.0679 - val_acc: 0.3333\n",
      "Running Fold 2 / 10\n",
      "Train on 360 samples, validate on 42 samples\n",
      "Epoch 1/20\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 1.4196 - acc: 0.3500 - val_loss: 1.3320 - val_acc: 0.3810\n",
      "Epoch 2/20\n",
      "360/360 [==============================] - 0s 278us/step - loss: 1.3595 - acc: 0.3444 - val_loss: 1.2942 - val_acc: 0.4048\n",
      "Epoch 3/20\n",
      "360/360 [==============================] - 0s 281us/step - loss: 1.3107 - acc: 0.3389 - val_loss: 1.2644 - val_acc: 0.4048\n",
      "Epoch 4/20\n",
      "360/360 [==============================] - 0s 260us/step - loss: 1.2699 - acc: 0.3444 - val_loss: 1.2417 - val_acc: 0.4048\n",
      "Epoch 5/20\n",
      "360/360 [==============================] - 0s 261us/step - loss: 1.2372 - acc: 0.3500 - val_loss: 1.2217 - val_acc: 0.3810\n",
      "Epoch 6/20\n",
      "360/360 [==============================] - 0s 275us/step - loss: 1.2105 - acc: 0.3500 - val_loss: 1.2071 - val_acc: 0.3810\n",
      "Epoch 7/20\n",
      "360/360 [==============================] - 0s 264us/step - loss: 1.1891 - acc: 0.3722 - val_loss: 1.1922 - val_acc: 0.3810\n",
      "Epoch 8/20\n",
      "360/360 [==============================] - 0s 278us/step - loss: 1.1720 - acc: 0.3917 - val_loss: 1.1834 - val_acc: 0.3571\n",
      "Epoch 9/20\n",
      "360/360 [==============================] - 0s 288us/step - loss: 1.1584 - acc: 0.3944 - val_loss: 1.1754 - val_acc: 0.3333\n",
      "Epoch 10/20\n",
      "360/360 [==============================] - 0s 253us/step - loss: 1.1466 - acc: 0.4056 - val_loss: 1.1672 - val_acc: 0.3333\n",
      "Epoch 11/20\n",
      "360/360 [==============================] - 0s 271us/step - loss: 1.1360 - acc: 0.4000 - val_loss: 1.1622 - val_acc: 0.3095\n",
      "Epoch 12/20\n",
      "360/360 [==============================] - 0s 263us/step - loss: 1.1274 - acc: 0.3972 - val_loss: 1.1578 - val_acc: 0.3333\n",
      "Epoch 13/20\n",
      "360/360 [==============================] - 0s 282us/step - loss: 1.1192 - acc: 0.4111 - val_loss: 1.1537 - val_acc: 0.3095\n",
      "Epoch 14/20\n",
      "360/360 [==============================] - 0s 293us/step - loss: 1.1123 - acc: 0.4083 - val_loss: 1.1500 - val_acc: 0.3333\n",
      "Epoch 15/20\n",
      "360/360 [==============================] - 0s 265us/step - loss: 1.1059 - acc: 0.4139 - val_loss: 1.1464 - val_acc: 0.3333\n",
      "Epoch 16/20\n",
      "360/360 [==============================] - 0s 259us/step - loss: 1.1006 - acc: 0.4167 - val_loss: 1.1439 - val_acc: 0.3333\n",
      "Epoch 17/20\n",
      "360/360 [==============================] - 0s 263us/step - loss: 1.0954 - acc: 0.4333 - val_loss: 1.1414 - val_acc: 0.3333\n",
      "Epoch 18/20\n",
      "360/360 [==============================] - 0s 256us/step - loss: 1.0909 - acc: 0.4250 - val_loss: 1.1393 - val_acc: 0.3333\n",
      "Epoch 19/20\n",
      "360/360 [==============================] - 0s 297us/step - loss: 1.0869 - acc: 0.4333 - val_loss: 1.1370 - val_acc: 0.3333\n",
      "Epoch 20/20\n",
      "360/360 [==============================] - 0s 270us/step - loss: 1.0834 - acc: 0.4361 - val_loss: 1.1355 - val_acc: 0.3571\n",
      "Running Fold 3 / 10\n",
      "Train on 361 samples, validate on 41 samples\n",
      "Epoch 1/20\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 1.5271 - acc: 0.2936 - val_loss: 1.4444 - val_acc: 0.3171\n",
      "Epoch 2/20\n",
      "361/361 [==============================] - 0s 295us/step - loss: 1.4626 - acc: 0.3130 - val_loss: 1.3962 - val_acc: 0.3171\n",
      "Epoch 3/20\n",
      "361/361 [==============================] - 0s 279us/step - loss: 1.4115 - acc: 0.3158 - val_loss: 1.3578 - val_acc: 0.2927\n",
      "Epoch 4/20\n",
      "361/361 [==============================] - 0s 248us/step - loss: 1.3698 - acc: 0.3324 - val_loss: 1.3244 - val_acc: 0.2927\n",
      "Epoch 5/20\n",
      "361/361 [==============================] - 0s 251us/step - loss: 1.3352 - acc: 0.3352 - val_loss: 1.2954 - val_acc: 0.2439\n",
      "Epoch 6/20\n",
      "361/361 [==============================] - 0s 274us/step - loss: 1.3060 - acc: 0.3463 - val_loss: 1.2701 - val_acc: 0.2683\n",
      "Epoch 7/20\n",
      "361/361 [==============================] - 0s 280us/step - loss: 1.2804 - acc: 0.3490 - val_loss: 1.2484 - val_acc: 0.2683\n",
      "Epoch 8/20\n",
      "361/361 [==============================] - 0s 290us/step - loss: 1.2579 - acc: 0.3629 - val_loss: 1.2276 - val_acc: 0.3171\n",
      "Epoch 9/20\n",
      "361/361 [==============================] - 0s 266us/step - loss: 1.2363 - acc: 0.3767 - val_loss: 1.2109 - val_acc: 0.3171\n",
      "Epoch 10/20\n",
      "361/361 [==============================] - 0s 249us/step - loss: 1.2186 - acc: 0.3712 - val_loss: 1.1957 - val_acc: 0.3415\n",
      "Epoch 11/20\n",
      "361/361 [==============================] - 0s 270us/step - loss: 1.2025 - acc: 0.3850 - val_loss: 1.1825 - val_acc: 0.3902\n",
      "Epoch 12/20\n",
      "361/361 [==============================] - 0s 280us/step - loss: 1.1879 - acc: 0.3712 - val_loss: 1.1713 - val_acc: 0.3902\n",
      "Epoch 13/20\n",
      "361/361 [==============================] - 0s 269us/step - loss: 1.1753 - acc: 0.3795 - val_loss: 1.1611 - val_acc: 0.3659\n",
      "Epoch 14/20\n",
      "361/361 [==============================] - 0s 305us/step - loss: 1.1642 - acc: 0.3795 - val_loss: 1.1517 - val_acc: 0.3659\n",
      "Epoch 15/20\n",
      "361/361 [==============================] - 0s 281us/step - loss: 1.1540 - acc: 0.3906 - val_loss: 1.1444 - val_acc: 0.3659\n",
      "Epoch 16/20\n",
      "361/361 [==============================] - 0s 251us/step - loss: 1.1451 - acc: 0.3934 - val_loss: 1.1364 - val_acc: 0.3659\n",
      "Epoch 17/20\n",
      "361/361 [==============================] - 0s 273us/step - loss: 1.1372 - acc: 0.4044 - val_loss: 1.1305 - val_acc: 0.3902\n",
      "Epoch 18/20\n",
      "361/361 [==============================] - 0s 254us/step - loss: 1.1298 - acc: 0.4044 - val_loss: 1.1235 - val_acc: 0.3902\n",
      "Epoch 19/20\n",
      "361/361 [==============================] - 0s 286us/step - loss: 1.1224 - acc: 0.3989 - val_loss: 1.1180 - val_acc: 0.3659\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 248us/step - loss: 1.1162 - acc: 0.4072 - val_loss: 1.1136 - val_acc: 0.3902\n",
      "Running Fold 4 / 10\n",
      "Train on 361 samples, validate on 41 samples\n",
      "Epoch 1/20\n",
      "361/361 [==============================] - 1s 2ms/step - loss: 1.5514 - acc: 0.3130 - val_loss: 1.5405 - val_acc: 0.1463\n",
      "Epoch 2/20\n",
      "361/361 [==============================] - 0s 266us/step - loss: 1.4757 - acc: 0.3075 - val_loss: 1.4782 - val_acc: 0.1463\n",
      "Epoch 3/20\n",
      "361/361 [==============================] - 0s 251us/step - loss: 1.4151 - acc: 0.3186 - val_loss: 1.4289 - val_acc: 0.1220\n",
      "Epoch 4/20\n",
      "361/361 [==============================] - ETA: 0s - loss: 1.3126 - acc: 0.312 - 0s 299us/step - loss: 1.3669 - acc: 0.3075 - val_loss: 1.3900 - val_acc: 0.1463\n",
      "Epoch 5/20\n",
      "361/361 [==============================] - 0s 263us/step - loss: 1.3293 - acc: 0.2992 - val_loss: 1.3549 - val_acc: 0.1951\n",
      "Epoch 6/20\n",
      "361/361 [==============================] - 0s 272us/step - loss: 1.2968 - acc: 0.3186 - val_loss: 1.3279 - val_acc: 0.1951\n",
      "Epoch 7/20\n",
      "361/361 [==============================] - 0s 236us/step - loss: 1.2717 - acc: 0.3269 - val_loss: 1.3047 - val_acc: 0.2195\n",
      "Epoch 8/20\n",
      "361/361 [==============================] - 0s 302us/step - loss: 1.2494 - acc: 0.3435 - val_loss: 1.2814 - val_acc: 0.2683\n",
      "Epoch 9/20\n",
      "361/361 [==============================] - 0s 313us/step - loss: 1.2305 - acc: 0.3407 - val_loss: 1.2654 - val_acc: 0.2683\n",
      "Epoch 10/20\n",
      "361/361 [==============================] - 0s 265us/step - loss: 1.2133 - acc: 0.3518 - val_loss: 1.2467 - val_acc: 0.2927\n",
      "Epoch 11/20\n",
      "361/361 [==============================] - 0s 254us/step - loss: 1.1974 - acc: 0.3490 - val_loss: 1.2331 - val_acc: 0.2927\n",
      "Epoch 12/20\n",
      "361/361 [==============================] - 0s 292us/step - loss: 1.1844 - acc: 0.3629 - val_loss: 1.2199 - val_acc: 0.2927\n",
      "Epoch 13/20\n",
      "361/361 [==============================] - 0s 273us/step - loss: 1.1726 - acc: 0.3601 - val_loss: 1.2076 - val_acc: 0.3171\n",
      "Epoch 14/20\n",
      "361/361 [==============================] - 0s 276us/step - loss: 1.1618 - acc: 0.3740 - val_loss: 1.1938 - val_acc: 0.3171\n",
      "Epoch 15/20\n",
      "361/361 [==============================] - 0s 295us/step - loss: 1.1503 - acc: 0.3878 - val_loss: 1.1840 - val_acc: 0.3171\n",
      "Epoch 16/20\n",
      "361/361 [==============================] - 0s 274us/step - loss: 1.1409 - acc: 0.3906 - val_loss: 1.1775 - val_acc: 0.3415\n",
      "Epoch 17/20\n",
      "361/361 [==============================] - 0s 266us/step - loss: 1.1321 - acc: 0.3906 - val_loss: 1.1707 - val_acc: 0.3415\n",
      "Epoch 18/20\n",
      "361/361 [==============================] - 0s 254us/step - loss: 1.1248 - acc: 0.3961 - val_loss: 1.1626 - val_acc: 0.3171\n",
      "Epoch 19/20\n",
      "361/361 [==============================] - ETA: 0s - loss: 1.1242 - acc: 0.408 - 0s 293us/step - loss: 1.1178 - acc: 0.4155 - val_loss: 1.1566 - val_acc: 0.3171\n",
      "Epoch 20/20\n",
      "361/361 [==============================] - 0s 240us/step - loss: 1.1115 - acc: 0.4266 - val_loss: 1.1496 - val_acc: 0.3171\n",
      "Running Fold 5 / 10\n",
      "Train on 362 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 1.2942 - acc: 0.3149 - val_loss: 1.3843 - val_acc: 0.3750\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 0s 267us/step - loss: 1.2561 - acc: 0.3315 - val_loss: 1.3509 - val_acc: 0.4250\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 0s 223us/step - loss: 1.2269 - acc: 0.3287 - val_loss: 1.3265 - val_acc: 0.4500\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 0s 278us/step - loss: 1.2047 - acc: 0.3453 - val_loss: 1.3064 - val_acc: 0.4500\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 0s 260us/step - loss: 1.1862 - acc: 0.3508 - val_loss: 1.2903 - val_acc: 0.4750\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 0s 256us/step - loss: 1.1711 - acc: 0.3646 - val_loss: 1.2776 - val_acc: 0.4500\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 0s 257us/step - loss: 1.1586 - acc: 0.3619 - val_loss: 1.2655 - val_acc: 0.4500\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 0s 265us/step - loss: 1.1484 - acc: 0.3923 - val_loss: 1.2549 - val_acc: 0.4750\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 0s 243us/step - loss: 1.1399 - acc: 0.4033 - val_loss: 1.2458 - val_acc: 0.4750\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 0s 242us/step - loss: 1.1321 - acc: 0.4006 - val_loss: 1.2377 - val_acc: 0.4250\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 0s 231us/step - loss: 1.1254 - acc: 0.4006 - val_loss: 1.2307 - val_acc: 0.4500\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 0s 253us/step - loss: 1.1208 - acc: 0.4033 - val_loss: 1.2238 - val_acc: 0.4250\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 0s 250us/step - loss: 1.1151 - acc: 0.4006 - val_loss: 1.2175 - val_acc: 0.4250\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 0s 253us/step - loss: 1.1107 - acc: 0.4033 - val_loss: 1.2106 - val_acc: 0.4000\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 0s 217us/step - loss: 1.1063 - acc: 0.4171 - val_loss: 1.2051 - val_acc: 0.3500\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 0s 229us/step - loss: 1.1025 - acc: 0.4171 - val_loss: 1.1992 - val_acc: 0.3500\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 0s 252us/step - loss: 1.0997 - acc: 0.4199 - val_loss: 1.1952 - val_acc: 0.3500\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 0s 275us/step - loss: 1.0963 - acc: 0.4199 - val_loss: 1.1909 - val_acc: 0.4000\n",
      "Epoch 19/20\n",
      "362/362 [==============================] - 0s 272us/step - loss: 1.0933 - acc: 0.4282 - val_loss: 1.1866 - val_acc: 0.4000\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 0s 267us/step - loss: 1.0908 - acc: 0.4282 - val_loss: 1.1834 - val_acc: 0.3750\n",
      "Running Fold 6 / 10\n",
      "Train on 362 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 1.4382 - acc: 0.2901 - val_loss: 1.4526 - val_acc: 0.3000\n",
      "Epoch 2/20\n",
      "362/362 [==============================] - 0s 245us/step - loss: 1.3776 - acc: 0.3094 - val_loss: 1.4086 - val_acc: 0.2750\n",
      "Epoch 3/20\n",
      "362/362 [==============================] - 0s 238us/step - loss: 1.3328 - acc: 0.3287 - val_loss: 1.3729 - val_acc: 0.2750\n",
      "Epoch 4/20\n",
      "362/362 [==============================] - 0s 231us/step - loss: 1.2975 - acc: 0.3260 - val_loss: 1.3441 - val_acc: 0.2750\n",
      "Epoch 5/20\n",
      "362/362 [==============================] - 0s 281us/step - loss: 1.2693 - acc: 0.3260 - val_loss: 1.3195 - val_acc: 0.2500\n",
      "Epoch 6/20\n",
      "362/362 [==============================] - 0s 246us/step - loss: 1.2443 - acc: 0.3343 - val_loss: 1.2989 - val_acc: 0.2500\n",
      "Epoch 7/20\n",
      "362/362 [==============================] - 0s 265us/step - loss: 1.2250 - acc: 0.3370 - val_loss: 1.2814 - val_acc: 0.2500\n",
      "Epoch 8/20\n",
      "362/362 [==============================] - 0s 261us/step - loss: 1.2082 - acc: 0.3453 - val_loss: 1.2651 - val_acc: 0.2500\n",
      "Epoch 9/20\n",
      "362/362 [==============================] - 0s 252us/step - loss: 1.1938 - acc: 0.3619 - val_loss: 1.2502 - val_acc: 0.2500\n",
      "Epoch 10/20\n",
      "362/362 [==============================] - 0s 263us/step - loss: 1.1808 - acc: 0.3646 - val_loss: 1.2368 - val_acc: 0.2750\n",
      "Epoch 11/20\n",
      "362/362 [==============================] - 0s 271us/step - loss: 1.1689 - acc: 0.3646 - val_loss: 1.2249 - val_acc: 0.2500\n",
      "Epoch 12/20\n",
      "362/362 [==============================] - 0s 276us/step - loss: 1.1589 - acc: 0.3895 - val_loss: 1.2141 - val_acc: 0.2750\n",
      "Epoch 13/20\n",
      "362/362 [==============================] - 0s 262us/step - loss: 1.1496 - acc: 0.3895 - val_loss: 1.2043 - val_acc: 0.2750\n",
      "Epoch 14/20\n",
      "362/362 [==============================] - 0s 231us/step - loss: 1.1406 - acc: 0.3950 - val_loss: 1.1944 - val_acc: 0.3500\n",
      "Epoch 15/20\n",
      "362/362 [==============================] - 0s 252us/step - loss: 1.1328 - acc: 0.4033 - val_loss: 1.1854 - val_acc: 0.3500\n",
      "Epoch 16/20\n",
      "362/362 [==============================] - 0s 239us/step - loss: 1.1255 - acc: 0.4061 - val_loss: 1.1777 - val_acc: 0.3500\n",
      "Epoch 17/20\n",
      "362/362 [==============================] - 0s 267us/step - loss: 1.1191 - acc: 0.4144 - val_loss: 1.1703 - val_acc: 0.3500\n",
      "Epoch 18/20\n",
      "362/362 [==============================] - 0s 252us/step - loss: 1.1128 - acc: 0.4116 - val_loss: 1.1638 - val_acc: 0.3500\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/362 [==============================] - 0s 246us/step - loss: 1.1077 - acc: 0.4199 - val_loss: 1.1577 - val_acc: 0.3500\n",
      "Epoch 20/20\n",
      "362/362 [==============================] - 0s 271us/step - loss: 1.1031 - acc: 0.4227 - val_loss: 1.1514 - val_acc: 0.3500\n",
      "Running Fold 7 / 10\n",
      "Train on 363 samples, validate on 39 samples\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6831 - acc: 0.2893 - val_loss: 1.7026 - val_acc: 0.2308\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 280us/step - loss: 1.5595 - acc: 0.3030 - val_loss: 1.6086 - val_acc: 0.2564\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 259us/step - loss: 1.4593 - acc: 0.3030 - val_loss: 1.5327 - val_acc: 0.2564\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 241us/step - loss: 1.3824 - acc: 0.3140 - val_loss: 1.4681 - val_acc: 0.2821\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 265us/step - loss: 1.3222 - acc: 0.3223 - val_loss: 1.4159 - val_acc: 0.2821\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 248us/step - loss: 1.2770 - acc: 0.3333 - val_loss: 1.3717 - val_acc: 0.2821\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 245us/step - loss: 1.2425 - acc: 0.3278 - val_loss: 1.3360 - val_acc: 0.3077\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 263us/step - loss: 1.2166 - acc: 0.3251 - val_loss: 1.3054 - val_acc: 0.3333\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 276us/step - loss: 1.1956 - acc: 0.3444 - val_loss: 1.2796 - val_acc: 0.3077\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 254us/step - loss: 1.1783 - acc: 0.3581 - val_loss: 1.2585 - val_acc: 0.2821\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 249us/step - loss: 1.1651 - acc: 0.3636 - val_loss: 1.2406 - val_acc: 0.3077\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 251us/step - loss: 1.1533 - acc: 0.3664 - val_loss: 1.2250 - val_acc: 0.2821\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 237us/step - loss: 1.1435 - acc: 0.3664 - val_loss: 1.2118 - val_acc: 0.2821\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 267us/step - loss: 1.1347 - acc: 0.3802 - val_loss: 1.1997 - val_acc: 0.2821\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 256us/step - loss: 1.1278 - acc: 0.3939 - val_loss: 1.1893 - val_acc: 0.2821\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 230us/step - loss: 1.1206 - acc: 0.4077 - val_loss: 1.1797 - val_acc: 0.2821\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 269us/step - loss: 1.1147 - acc: 0.4132 - val_loss: 1.1713 - val_acc: 0.3077\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 247us/step - loss: 1.1091 - acc: 0.4050 - val_loss: 1.1641 - val_acc: 0.3077\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 258us/step - loss: 1.1044 - acc: 0.4160 - val_loss: 1.1575 - val_acc: 0.3077\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 258us/step - loss: 1.1002 - acc: 0.4187 - val_loss: 1.1510 - val_acc: 0.3333\n",
      "Running Fold 8 / 10\n",
      "Train on 363 samples, validate on 39 samples\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3000 - acc: 0.3857 - val_loss: 1.1919 - val_acc: 0.5641\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 283us/step - loss: 1.2644 - acc: 0.3719 - val_loss: 1.1803 - val_acc: 0.5385\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 257us/step - loss: 1.2377 - acc: 0.3857 - val_loss: 1.1726 - val_acc: 0.5385\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 252us/step - loss: 1.2163 - acc: 0.4050 - val_loss: 1.1663 - val_acc: 0.5385\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 276us/step - loss: 1.1987 - acc: 0.4050 - val_loss: 1.1618 - val_acc: 0.5385\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 291us/step - loss: 1.1838 - acc: 0.4160 - val_loss: 1.1577 - val_acc: 0.5128\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 254us/step - loss: 1.1711 - acc: 0.4132 - val_loss: 1.1548 - val_acc: 0.4872\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 244us/step - loss: 1.1604 - acc: 0.4050 - val_loss: 1.1517 - val_acc: 0.4872\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 269us/step - loss: 1.1516 - acc: 0.4077 - val_loss: 1.1494 - val_acc: 0.4615\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 277us/step - loss: 1.1428 - acc: 0.4105 - val_loss: 1.1468 - val_acc: 0.4872\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 274us/step - loss: 1.1352 - acc: 0.4050 - val_loss: 1.1447 - val_acc: 0.4615\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 274us/step - loss: 1.1288 - acc: 0.4022 - val_loss: 1.1418 - val_acc: 0.4359\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 243us/step - loss: 1.1232 - acc: 0.4077 - val_loss: 1.1391 - val_acc: 0.4359\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 255us/step - loss: 1.1175 - acc: 0.4105 - val_loss: 1.1366 - val_acc: 0.4359\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 237us/step - loss: 1.1132 - acc: 0.4077 - val_loss: 1.1347 - val_acc: 0.4359\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 230us/step - loss: 1.1085 - acc: 0.4187 - val_loss: 1.1331 - val_acc: 0.4615\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 281us/step - loss: 1.1041 - acc: 0.4132 - val_loss: 1.1302 - val_acc: 0.4615\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 261us/step - loss: 1.1003 - acc: 0.4187 - val_loss: 1.1282 - val_acc: 0.4615\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 251us/step - loss: 1.0969 - acc: 0.4187 - val_loss: 1.1264 - val_acc: 0.4615\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 280us/step - loss: 1.0933 - acc: 0.4187 - val_loss: 1.1250 - val_acc: 0.4872\n",
      "Running Fold 9 / 10\n",
      "Train on 363 samples, validate on 39 samples\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4244 - acc: 0.3223 - val_loss: 1.3517 - val_acc: 0.3077\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 267us/step - loss: 1.3447 - acc: 0.3306 - val_loss: 1.3043 - val_acc: 0.3333\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 259us/step - loss: 1.2898 - acc: 0.3444 - val_loss: 1.2716 - val_acc: 0.3333\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 272us/step - loss: 1.2505 - acc: 0.3526 - val_loss: 1.2480 - val_acc: 0.3077\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 287us/step - loss: 1.2224 - acc: 0.3636 - val_loss: 1.2313 - val_acc: 0.3077\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 272us/step - loss: 1.2010 - acc: 0.3581 - val_loss: 1.2173 - val_acc: 0.3333\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 269us/step - loss: 1.1832 - acc: 0.3526 - val_loss: 1.2061 - val_acc: 0.3333\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 248us/step - loss: 1.1682 - acc: 0.3471 - val_loss: 1.1963 - val_acc: 0.2564\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 287us/step - loss: 1.1557 - acc: 0.3554 - val_loss: 1.1876 - val_acc: 0.2821\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 280us/step - loss: 1.1442 - acc: 0.3664 - val_loss: 1.1801 - val_acc: 0.2821\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 284us/step - loss: 1.1341 - acc: 0.3829 - val_loss: 1.1733 - val_acc: 0.3077\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 258us/step - loss: 1.1256 - acc: 0.3857 - val_loss: 1.1675 - val_acc: 0.3077\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 272us/step - loss: 1.1180 - acc: 0.3829 - val_loss: 1.1625 - val_acc: 0.3077\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 256us/step - loss: 1.1111 - acc: 0.3912 - val_loss: 1.1575 - val_acc: 0.3333\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 267us/step - loss: 1.1046 - acc: 0.3939 - val_loss: 1.1529 - val_acc: 0.3590\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 284us/step - loss: 1.0990 - acc: 0.3829 - val_loss: 1.1488 - val_acc: 0.3590\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 274us/step - loss: 1.0943 - acc: 0.3967 - val_loss: 1.1454 - val_acc: 0.3846\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 316us/step - loss: 1.0896 - acc: 0.4050 - val_loss: 1.1425 - val_acc: 0.4103\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 313us/step - loss: 1.0858 - acc: 0.4187 - val_loss: 1.1392 - val_acc: 0.4103\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 281us/step - loss: 1.0819 - acc: 0.4215 - val_loss: 1.1365 - val_acc: 0.4103\n",
      "Running Fold 10 / 10\n",
      "Train on 363 samples, validate on 39 samples\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.5719 - acc: 0.3196 - val_loss: 1.4648 - val_acc: 0.2308\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 288us/step - loss: 1.5127 - acc: 0.3223 - val_loss: 1.3901 - val_acc: 0.2564\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 287us/step - loss: 1.4621 - acc: 0.3140 - val_loss: 1.3323 - val_acc: 0.2821\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 316us/step - loss: 1.4191 - acc: 0.3306 - val_loss: 1.2867 - val_acc: 0.3333\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 281us/step - loss: 1.3817 - acc: 0.3333 - val_loss: 1.2484 - val_acc: 0.3333\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 296us/step - loss: 1.3482 - acc: 0.3361 - val_loss: 1.2204 - val_acc: 0.3333\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 278us/step - loss: 1.3188 - acc: 0.3278 - val_loss: 1.1962 - val_acc: 0.3333\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 247us/step - loss: 1.2929 - acc: 0.3306 - val_loss: 1.1767 - val_acc: 0.3590\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 266us/step - loss: 1.2692 - acc: 0.3388 - val_loss: 1.1603 - val_acc: 0.3846\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 313us/step - loss: 1.2490 - acc: 0.3388 - val_loss: 1.1464 - val_acc: 0.3846\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 287us/step - loss: 1.2318 - acc: 0.3444 - val_loss: 1.1359 - val_acc: 0.3846\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 289us/step - loss: 1.2157 - acc: 0.3471 - val_loss: 1.1273 - val_acc: 0.4359\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 287us/step - loss: 1.2017 - acc: 0.3554 - val_loss: 1.1191 - val_acc: 0.4359\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 269us/step - loss: 1.1887 - acc: 0.3664 - val_loss: 1.1122 - val_acc: 0.4615\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 283us/step - loss: 1.1770 - acc: 0.3884 - val_loss: 1.1070 - val_acc: 0.4615\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 277us/step - loss: 1.1664 - acc: 0.3802 - val_loss: 1.1028 - val_acc: 0.4872\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 273us/step - loss: 1.1571 - acc: 0.3884 - val_loss: 1.0990 - val_acc: 0.4872\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 296us/step - loss: 1.1483 - acc: 0.3774 - val_loss: 1.0960 - val_acc: 0.4872\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 267us/step - loss: 1.1403 - acc: 0.3857 - val_loss: 1.0937 - val_acc: 0.4872\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 369us/step - loss: 1.1330 - acc: 0.3884 - val_loss: 1.0915 - val_acc: 0.4872\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "\n",
    "labels = df['flow_rate'].values\n",
    "data = x\n",
    "\n",
    "labels[labels == 1800] = 0\n",
    "labels[labels == 3600] = 1\n",
    "labels[labels == 7200] = 2\n",
    "\n",
    "labels = np_utils.to_categorical(labels, nb_classes) \n",
    "\n",
    "skf = StratifiedKFold(df['flow_rate'].values, n_folds=n_folds, shuffle=True)\n",
    "avg_acc = 0\n",
    "\n",
    "for i, (train, test) in enumerate(skf):\n",
    "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    model = None # Clearing the NN.\n",
    "    model = build_logistic_model(input_dim, nb_classes)\n",
    "    \n",
    "    std = np.std(data[train],0)\n",
    "    mean = np.mean(data[train],0)\n",
    "    \n",
    "    x_train = (data[train]-mean)/std\n",
    "    x_test = (data[test] - mean)/std        \n",
    "    \n",
    "    avg_acc += train_and_evaluate_model(model, x_train, labels[train], x_test, labels[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score:  0.3840741996038836\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Score: \", avg_acc/n_folds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
