{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duo\\Anaconda3\\envs\\fastai\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pylab as plt\n",
    "from keras.utils import np_utils \n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\\"\n",
    "source_path = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\cropped\\\\\"\n",
    "csv = \"I:\\\\Honours-Project\\\\data\\\\sorted\\\\agg\\\\ids.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv,index_col=0).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flow_rate\n",
      "1800    116\n",
      "3600    116\n",
      "7200    116\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ds_count = min(df.groupby('flow_rate').size())\n",
    "ds_flow = df.groupby('flow_rate').size().idxmin()\n",
    "\n",
    "samples = pd.concat([df[df['flow_rate']==i].sample(n=ds_count) for i in (1800,3600,7200)],ignore_index=True)\n",
    "\n",
    "df = samples.sample(frac=1)\n",
    "\n",
    "print(df.groupby('flow_rate').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "df['log_volume'] = df['volume'].apply(np.log)\n",
    "\n",
    "mat = df.drop(columns=['name','date','flow_rate','source','moments','inertia_tensor'])\n",
    "\n",
    "# Drop catagorical features\n",
    "mat = mat.drop(columns=['cluster'])\n",
    "\n",
    "X = mat.as_matrix()\n",
    "# x = standardize = preprocessing.scale(x)\n",
    "\n",
    "y = df[\"flow_rate\"].values\n",
    "\n",
    "y[y == 1800] = 0\n",
    "y[y == 3600] = 1\n",
    "y[y == 7200] = 2\n",
    "\n",
    "one_hot = np_utils.to_categorical(df[\"flow_rate\"].values, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, one_hot, test_size=36, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tree = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier():\n",
    "    if random_tree:\n",
    "        return RandomForestClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.1, \n",
    "                       min_samples_leaf=4, min_samples_split=9, n_estimators=100, verbose=1)\n",
    "    else:\n",
    "        return GradientBoostingClassifier(max_features=0.1, \n",
    "                       min_samples_leaf=4, min_samples_split=9, n_estimators=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.1, \n",
    "                       min_samples_leaf=4, min_samples_split=9, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 10\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         335.5689            0.30s\n",
      "         2         329.8815            0.24s\n",
      "         3         325.8824            0.23s\n",
      "         4         319.6191            0.24s\n",
      "         5         315.8743            0.23s\n",
      "         6         309.8680            0.22s\n",
      "         7         305.9266            0.21s\n",
      "         8         301.0551            0.22s\n",
      "         9         295.6959            0.21s\n",
      "        10         291.6159            0.21s\n",
      "        20         259.1565            0.16s\n",
      "        30         233.4670            0.14s\n",
      "        40         207.4298            0.12s\n",
      "        50         188.2037            0.09s\n",
      "        60         170.8546            0.07s\n",
      "        70         154.4560            0.06s\n",
      "        80         141.2250            0.04s\n",
      "        90         128.5144            0.02s\n",
      "       100         118.8926            0.00s\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e78326822b0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Convert predictions classes to one hot vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mY_pred_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Convert validation observations to one hot vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mY_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \"\"\"\n\u001b[1;32m-> 1004\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "avg_acc = 0\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train, test in skf.split(X,y):\n",
    "    print(\"Running Fold\", i+1, \"/\", n_folds)\n",
    "    i+=1\n",
    "    \n",
    "    std = np.std(X[train],0)\n",
    "    mean = np.mean(X[train],0)\n",
    "            \n",
    "    X_train = (X[train] - mean)/std\n",
    "    X_test = (X[test] - mean)/std \n",
    "        \n",
    "    y_train = one_hot[train]\n",
    "            \n",
    "    model = None # Clearing the NN.\n",
    "    model = get_classifier()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "            \n",
    "    # Predict the values from the validation dataset\n",
    "    Y_pred = model.predict(X_test)\n",
    "    # Convert predictions classes to one hot vectors \n",
    "    Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "    # Convert validation observations to one hot vectors\n",
    "    Y_true = np.argmax(one_hot[test],axis = 1) \n",
    "    \n",
    "    y_true.extend(Y_true)\n",
    "    y_pred.extend(Y_pred_classes)\n",
    "    \n",
    "    print(\"Accuracy: \", sum(Y_pred_classes == Y_true)/len(Y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(np.array(y_true), np.array(y_pred)) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
